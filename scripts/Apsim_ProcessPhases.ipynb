{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Growth Phases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks at the SQLite Databases generated by Apsim X (Next Gen) for 109 Wheat varieties, 10 differing sow dates for  57,434 locations/sites across Australia.  \n",
    "Each database file covers one (1) site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the working directories\n",
    "apsim_sourcedir = \"/OSM/CBR/AG_WHEATTEMP/source\"\n",
    "apsim_outfiledir = \"/OSM/CBR/AG_WHEATTEMP/work/output\"\n",
    "metfile_sourcedir = \"/OSM/CBR/AG_WHEATTEMP/work/ApsimNG-test/APSIM_run/met\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbfile_df = pd.DataFrame(columns=['filename'])\n",
    "dbfile_df.filename = sorted(apsim_sourcedir+'/'+f for f in os.listdir(apsim_sourcedir) if f.endswith('.db'))\n",
    "print(dbfile_df.head())\n",
    "dbname = print(dbfile_df.filename[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_ApsimWeather(filename):\n",
    "    '''\n",
    "    Reads an apsim weather ('.met') file, removes the header information,\n",
    "    calculates and adds a date column (based on year and day), and the\n",
    "    average temperature (based on maxt and mint).\n",
    "    '''\n",
    "\n",
    "    lineNo = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            lineNo = lineNo + 1\n",
    "            if line.startswith('year'):\n",
    "                break;\n",
    "\n",
    "    # return the data using the starting line no (determined above)\n",
    "    # original column names=['year','day', 'radn', 'maxt', 'mint', 'rain']\n",
    "    metData = pd.read_table(filename, sep='\\s+', header=None, skiprows=lineNo+1,\n",
    "                            names=['year','dayofYear', 'radiation', 'maxTemp', 'minTemp', 'rain'])\n",
    "\n",
    "    # add the calculated columns\n",
    "    metData['runDate'] = pd.to_datetime(metData['year'].astype(str) + \" \" + metData['dayofYear'].astype(str), format=\"%Y %j\")\n",
    "\n",
    "    # this may need to be the thermal time, not just average temp\n",
    "    metData['avgTemp'] = (metData['maxTemp'] + metData['minTemp']) / 2\n",
    "\n",
    "    # sort the columns to be a little more logical\n",
    "    cols=['year', 'dayofYear', 'runDate', 'maxTemp', 'minTemp', 'avgTemp', 'rain', 'radiation']\n",
    "    metData = metData[cols]\n",
    "\n",
    "    return metData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_simulation_details(dbname):\n",
    "    '''\n",
    "    Opens the specified SQL Database and extracts the 'Name' details from the Simulation\n",
    "    Table, and splits it to Simulation ID, Longitude, Latitude, Variety, SowDate, and\n",
    "    returns ad dataframe.\n",
    "    '''\n",
    "\n",
    "    # connect to the Database\n",
    "    con = sqlite3.connect(dbname)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # get contents of the _Simulation Table\n",
    "    strSql = \"SELECT ID as SimulationID, Name FROM _Simulations\"\n",
    "    dfSim = pd.read_sql_query(strSql, con, index_col = 'SimulationID')\n",
    "\n",
    "    # split the 'Name' field into long, lat, variety and sowdate columns\n",
    "    dfSim[['long','lat','variety','sowdate']] = \\\n",
    "    dfSim['Name'].str.extract(\"^(?P<long>\\d+)_(?P<lat>-?\\d+)_(?P<variety>\\S+)_(?P<sowdate>\\d+-\\S+)$\", expand=True)\n",
    "\n",
    "    # format the columns\n",
    "    pd.options.display.float_format = '{:,.2f}'.format\n",
    "    dfSim['long'] = dfSim['long'].astype(float) / 100\n",
    "    dfSim['lat'] = dfSim['lat'].astype(float) / 100\n",
    "\n",
    "    # create a SimId column (as the original SimulationID is now an index column)\n",
    "    dfSim['SimID'] = dfSim.index \n",
    "\n",
    "    return dfSim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_report_details(dbname):\n",
    "    '''\n",
    "    Opens the specified SQL Database and extracts the details from the Report\n",
    "    Table, formats the columns correctly and returns a dataframe\n",
    "    '''\n",
    "\n",
    "    # connect to the Database\n",
    "    con = sqlite3.connect(dbname)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # get contents of the Report Table\n",
    "    #strSql = \"SELECT SimulationID, substr([Clock.Today], 1, 10) as runDate, \\\n",
    "    #      [Wheat.Leaf.LAI] as LeafLAI, [Wheat.AboveGround.Wt] as AboveGroundWeight, \\\n",
    "    #      [Wheat.Grain.Wt] as GrainWeight, [Wheat.Phenology.Zadok.Stage] as ZadokStage, \\\n",
    "    #      [Wheat.WaterSupplyDemandRatio] as WaterSupplyDemandRatio, \\\n",
    "    #      [Wheat.Root.NUptake] as RootNUptake, [Wheat.Leaf.Fn] as LeafFn \\\n",
    "    #      FROM Report \\\n",
    "    #      ORDER BY SimulationID, runDate\"\n",
    "\n",
    "    #do not need all of the columns, will cut this down from the get go\n",
    "    strSql = \"SELECT SimulationID, substr([Clock.Today], 1, 10) as runDate, \\\n",
    "          [Wheat.Phenology.Zadok.Stage] as ZadokStage, \\\n",
    "          [Wheat.WaterSupplyDemandRatio] as WaterSupplyDemandRatio \\\n",
    "          FROM Report \\\n",
    "          ORDER BY SimulationID, runDate\"    \n",
    "    #print(datetime.datetime.now())\n",
    "    dfReport = pd.read_sql_query(strSql, con, index_col=\"SimulationID\" )\n",
    "    #print(datetime.datetime.now())\n",
    "\n",
    "    # format the date columns\n",
    "    dfReport['runDate'] = pd.to_datetime(dfReport['runDate'], format=\"%Y-%m-%d\")\n",
    "\n",
    "    # create the SimId column\n",
    "    dfReport['SimID'] = dfReport.index\n",
    "\n",
    "    return dfReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filename(dbname):\n",
    "    '''\n",
    "    Takes the full path and filename for the database file, and creates the filename\n",
    "    that is used for the weather file, and to save the output.\n",
    "\n",
    "    Note:  cannot use the db filename as it doesn't have the long & lat that we require\n",
    "           need to manipulate the filename to add the underscrore '_' char\n",
    "    '''\n",
    "    filename = os.path.basename(dbname)\n",
    "    filename = os.path.splitext(filename)[0]\n",
    "    nameparts = filename.split('-')\n",
    "    filename = nameparts[0] + '_-' + nameparts[1]\n",
    "\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weather_details(filename):\n",
    "    '''\n",
    "    Retrieves the weather data for the location (long,lat) specified in the dbname,\n",
    "    formats the data, and returns a dataframe\n",
    "    '''\n",
    "\n",
    "    fullfilename = metfile_sourcedir + \"/c_\" + filename + \".met\"\n",
    "    dfWeather = read_ApsimWeather(fullfilename)\n",
    "\n",
    "    return dfWeather\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data\n",
    "The following forms a single function:  def process_Apsim_dbfile(dbname):  \n",
    "#### NOTE:  dbname is defined at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"processing file: \", dbname)\n",
    "print(\"started at \", datetime.datetime.now())\n",
    "\n",
    "# retrieve the Simulation Details from the DB._Sumulation table\n",
    "dfSim = get_simulation_details(dbname) \n",
    "#print(dfSim.shape)\n",
    "#print(dfSim.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrieve the weather data from the weather '.met' file\n",
    "filename = get_filename(dbname)\n",
    "dfWeather = get_weather_details(filename)\n",
    "#print(dfWeather.shape)\n",
    "#print(dfWeather.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrieve the Details from the DB.Report table\n",
    "dfReport = get_report_details(dbname)\n",
    "#print(dfReport.shape)\n",
    "#print(dfReport.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine the report data with the weather data\n",
    "dfCombined = dfReport.merge(dfWeather, on='runDate', how='left')\n",
    "\n",
    "# filter the data based on the information we want\n",
    "filterCols = ['SimID', 'runDate', 'ZadokStage', 'avgTemp']\n",
    "dfSubData = dfCombined[filterCols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine the data with the Simulation details, so that we can get the sow date\n",
    "# and filter it again\n",
    "dfSubData = dfSubData.merge(dfSim, on=\"SimID\", how='left')\n",
    "filterCols = ['SimID', 'runDate', 'ZadokStage', 'avgTemp', 'sowdate']\n",
    "dfSubData = dfSubData[filterCols]\n",
    "\n",
    "# create a sowing date (with current year)\n",
    "dfSubData['sowingdate'] = dfSubData['sowdate'] + '-' + dfSubData['runDate'].dt.year.map(str)\n",
    "dfSubData['sowingdate'] = pd.to_datetime(dfSubData['sowingdate'], format=\"%d-%b-%Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now calculate the cumulative temp info for each simulation\n",
    "dfSubData['tempavgTemp'] = dfSubData['avgTemp'].where((dfSubData['runDate'] >= dfSubData['sowingdate']) \n",
    "                                                      & (dfSubData['ZadokStage'] > 0) \n",
    "                                                      & (dfSubData['ZadokStage'] <= 70), 0)\n",
    "dfSubData['cumAvgTemp'] = dfSubData.groupby(by=['SimID','sowingdate'])['tempavgTemp'].cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Need to determine the phases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter the data on the tempavgTemp column\n",
    "newData = dfSubData[dfSubData['tempavgTemp'] > 0]\n",
    "newData1 = newData.groupby(['SimID','sowdate'])['cumAvgTemp'].max().reset_index()\n",
    "newData2 = newData1.groupby(['SimID','sowdate'])['cumAvgTemp'].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to add back in the longitude, latitude, variety from dfSim\n",
    "newData2 = newData2.merge(dfSim, on=['SimID', 'sowdate'], how='left')\n",
    "filterCols = ['SimID', 'long', 'lat', 'variety', 'sowdate', 'cumAvgTemp']\n",
    "newData2 = newData2[filterCols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfilename = apsim_outfiledir + \"/\" + filename + \"_zadok.csv\"\n",
    "newData2.to_csv(outfilename, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
