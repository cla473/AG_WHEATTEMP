{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Growth Phases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks at the SQLite Databases generated by Apsim X (Next Gen) for 109 Wheat varieties, 10 differing sow dates for  57,434 locations/sites across Australia.  \n",
    "Each database file covers one (1) site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the working directories and set some default variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the working directories\n",
    "apsim_sourcedir = \"/OSM/CBR/AG_WHEATTEMP/source\"\n",
    "apsim_outfiledir = \"/OSM/CBR/AG_WHEATTEMP/work/output\"\n",
    "metfile_sourcedir = \"/OSM/CBR/AG_WHEATTEMP/work/ApsimNG-test/APSIM_run/met\"\n",
    "\n",
    "startDate = pd.to_datetime(\"1957-01-01\", format=\"%Y-%m-%d\")\n",
    "endDate = pd.to_datetime(\"2016-12-31\", format=\"%Y-%m-%d\")\n",
    "varietylist = ['agt_katana','agt_scythe','axe','baxter','bolac','ega_gregory',\n",
    "               'ega_wylie','h46','h45','janz','lancer','mace','sentinel','sunbri',\n",
    "               'sunstate','sunvale','ventura','westonia','yitpi']\n",
    "sowDateList=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following reads the directory specified and gets names of the '.db' files so that they can be processed.  \n",
    "However, in this instance we are only going to be working with one file.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile_df = pd.DataFrame(columns=['filename'])\n",
    "dbfile_df.filename = sorted(apsim_sourcedir+'/'+f for f in os.listdir(apsim_sourcedir) if f.endswith('.db'))\n",
    "print(dbfile_df.head())\n",
    "dbname = dbfile_df.filename[5]\n",
    "print(dbname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are some values that are required for calculation the Apsim Thermal Time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these are required for calculations of thermal time\n",
    "num3hr = int(24 / 3)\n",
    "#print(\"num3hr: \", num3hr)    \n",
    "t_range_fract = []\n",
    "\n",
    "# pre calculate t_range_fract for speed reasons\n",
    "for period in range(num3hr):\n",
    "    calcValue = 0.92105 \\\n",
    "                + 0.1140 * period \\\n",
    "                - 0.0703 * math.pow(period, 2) \\\n",
    "                + 0.0053 * math.pow(period, 3)\n",
    "    t_range_fract.append(calcValue)\n",
    "\n",
    "#print(\"t_range_fract: \", t_range_fract)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the functions required to retrieve data\n",
    "\n",
    "This section retrieves data from the database as well as the corresponding Apsim weather file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_variety_sowdate_for_location(long, lat):\n",
    "\n",
    "    longfloat = float(long)\n",
    "    latfloat = abs(float(lat))\n",
    "\n",
    "    if longfloat <= 129:\n",
    "        #this is Western Australia\n",
    "        variety = \"mace\"\n",
    "        sowDate = \"27-may\"\n",
    "    elif longfloat <= 141:\n",
    "        #this is South Australia\n",
    "        variety = \"janz\"\n",
    "        sowDate = \"27-may\"\n",
    "    else:\n",
    "        #these are the easter states\n",
    "        if latfloat >= 40:\n",
    "            #This is Tasmania\n",
    "            variety = \"thornbill\"\n",
    "            sowDate = \"16-apr\"\n",
    "        elif latfloat >= 35:\n",
    "            #This is an arbitrary line between Victoria and NSW\n",
    "            variety = \"janz\"\n",
    "            sowDate = \"27-may\"\n",
    "        elif latfloat >= 31:\n",
    "            #This is for Southern NSW\n",
    "            variety = \"chara\"\n",
    "            sowDate = \"13-may\"\n",
    "        elif latfloat >= 29:\n",
    "             #This is for Northern NSW\n",
    "            variety = \"baxter\"\n",
    "            sowDate = \"29-apr\"\n",
    "        elif latfloat >= 25:\n",
    "            #This is Southern Queensland\n",
    "            variety = \"ventura\"\n",
    "            sowDate = \"13-may\"\n",
    "        else:\n",
    "            #<25 This si for Northern Queensland\n",
    "            variety = \"ventura\"\n",
    "            sowDate = \"29-apr\"\n",
    "\n",
    "    return variety, sowDate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_variety_SimIDs(dfSim, varieties):\n",
    "    '''\n",
    "    Creates a list of SimulationIDs based on a list of varieties\n",
    "    '''\n",
    "    \n",
    "    dfSimVar = dfSim[dfSim['variety'].isin(varieties)]\n",
    "    #print(dfSimVar.shape)\n",
    "    #dfSimVar\n",
    "\n",
    "    #now create a list of the SimId's\n",
    "    simIds = dfSimVar.index.tolist()\n",
    "    simIdStr = ', '.join(str(e) for e in simIds)\n",
    "    \n",
    "    return simIdStr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_variety_SimID(dfSim, variety, sowdate):\n",
    "    '''\n",
    "    this will return a single Simulation ID based on a variety and sowdate\n",
    "    '''\n",
    "\n",
    "    dfSimVar = dfSim[(dfSim['variety'] == variety) & (dfSim['sowdate'] == sowdate)]\n",
    "\n",
    "    simIds = dfSimVar.index.tolist()\n",
    "    simIdStr = ', '.join(str(e) for e in simIds)\n",
    "    \n",
    "    return simIdStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_simulation_details(dbname):\n",
    "    '''\n",
    "    Opens the specified SQL Database and extracts the 'Name' details from the Simulation\n",
    "    Table, and splits it to Simulation ID, Longitude, Latitude, Variety, SowDate, and\n",
    "    returns ad dataframe.\n",
    "    '''\n",
    "\n",
    "    # connect to the Database\n",
    "    con = sqlite3.connect(dbname)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # get contents of the _Simulation Table\n",
    "    strSql = \"SELECT ID as SimulationID, Name FROM _Simulations\"\n",
    "    dfSim = pd.read_sql_query(strSql, con, index_col = 'SimulationID')\n",
    "\n",
    "    # split the 'Name' field into long, lat, variety and sowdate columns\n",
    "    dfSim[['long','lat','variety','sowdate']] = \\\n",
    "    dfSim['Name'].str.extract(\"^(?P<long>\\d+)_(?P<lat>-?\\d+)_(?P<variety>\\S+)_(?P<sowdate>\\d+-\\S+)$\", expand=True)\n",
    "\n",
    "    # format the columns\n",
    "    pd.options.display.float_format = '{:,.2f}'.format\n",
    "    dfSim['long'] = dfSim['long'].astype(float) / 100\n",
    "    dfSim['lat'] = dfSim['lat'].astype(float) / 100\n",
    "\n",
    "    # create a SimId column (as the original SimulationID is now an index column)\n",
    "    dfSim['SimID'] = dfSim.index \n",
    "\n",
    "    return dfSim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_report_details(dbname, simIdStr, startDate, endDate):\n",
    "    '''\n",
    "    Opens the specified SQL Database and extracts the details from the Report\n",
    "    Table, formats the columns correctly and returns a dataframe\n",
    "    '''\n",
    "\n",
    "    # connect to the Database\n",
    "    con = sqlite3.connect(dbname)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # get contents of the Report Table\n",
    "    #strSql = \"SELECT SimulationID, substr([Clock.Today], 1, 10) as runDate, \\\n",
    "    #      [Wheat.Leaf.LAI] as LAI, [Wheat.AboveGround.Wt] as Biomass, \\\n",
    "    #      [Wheat.Grain.Wt] as Yield, [Wheat.Phenology.Zadok.Stage] as ZadokStage, \\\n",
    "    #      [Wheat.WaterSupplyDemandRatio] as WaterSupplyDemandRatio, \\\n",
    "    #      [Wheat.Root.NUptake] as RootNUptake, [Wheat.Leaf.Fn] as LeafFn \\\n",
    "    #      FROM Report \\\n",
    "    #      ORDER BY SimulationID, runDate\"\n",
    "    \n",
    "    #Need to exclude consider CUTOFFS\n",
    "    #Need to use DISTINCT AS THERE SEEMS TO BE SOME DUPLICATIONS IN TO DATA\n",
    "\n",
    "    #do not need all of the columns, will cut this down from the get go\n",
    "    strSql = \"SELECT DISTINCT SimulationID, substr([Clock.Today], 1, 10) as runDate, \\\n",
    "          [Wheat.Leaf.LAI] as LAI, [Wheat.AboveGround.Wt] as Biomass, \\\n",
    "          [Wheat.Grain.Wt] as Yield, [Wheat.Phenology.Zadok.Stage] as ZadokStage, \\\n",
    "          [Wheat.WaterSupplyDemandRatio] as WSDR \\\n",
    "          FROM Report \\\n",
    "          WHERE SimulationID IN (\" + simIdStr + \") \\\n",
    "            AND [Wheat.Phenology.Zadok.Stage] > 0 \\\n",
    "          ORDER BY SimulationID, runDate\"    \n",
    "    #print(datetime.datetime.now())\n",
    "    dfReport = pd.read_sql_query(strSql, con, index_col=\"SimulationID\" )\n",
    "    #print(datetime.datetime.now())\n",
    "\n",
    "    # format the date columns\n",
    "    dfReport['runDate'] = pd.to_datetime(dfReport['runDate'], format=\"%Y-%m-%d\")\n",
    "\n",
    "    # create the SimId column\n",
    "    dfReport['SimID'] = dfReport.index\n",
    "    \n",
    "    #filter the data based on a date range\n",
    "    #do I need to make the run date an index column so tha we can quickly filter it\n",
    "    dfReport = dfReport[(dfReport['runDate'] >= startDate) & (dfReport['runDate'] <= endDate) ] \n",
    "\n",
    "    return dfReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filename(dbname):\n",
    "    '''\n",
    "    Takes the full path and filename for the database file, and creates the filename\n",
    "    that is used for the weather file, and to save the output.\n",
    "\n",
    "    Note:  cannot use the db filename as it doesn't have the long & lat that we require\n",
    "           need to manipulate the filename to add the underscrore '_' char\n",
    "           ONLY need to allow for negative (south) latitudes\n",
    "    '''\n",
    "    filename = os.path.basename(dbname)\n",
    "    filename = os.path.splitext(filename)[0]\n",
    "    nameparts = filename.split('-')\n",
    "    filename = nameparts[0] + '_-' + nameparts[1]\n",
    "    long = nameparts[0]\n",
    "    lat = '-' + nameparts[1]\n",
    "\n",
    "    return filename, long, lat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linint_3hrly_Temperature(tmax, tmin, xp, fp):\n",
    "    '''\n",
    "    Eight interpolations of the air temperature are calculated using \n",
    "    a three-hour correction factor.\n",
    "    For each air three-hour air temperature, a value is calculated.\n",
    "    The eight three-hour estimates are then averaged to obtain the daily value.\n",
    "    '''\n",
    "\n",
    "    #Local Variables\n",
    "    tot = 0.0            #sum_of of 3 hr interpolations\n",
    "    \n",
    "    for period in range(1, num3hr):\n",
    "        #get mean temperature for 3 hr period (oC)\n",
    "        tmean_3hour = tmin + (t_range_fract[period-1] * (tmax - tmin))\n",
    "        tot = tot + np.interp(tmean_3hour, xp,fp)\n",
    "        #print(\"tmean_3hour: \", tmean_3hour, \" - tot: \", tot)\n",
    "\n",
    "    return tot / num3hr;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_ApsimWeather(filename, latitude, startDate, endDate):\n",
    "    '''\n",
    "    Reads an apsim weather ('.met') file, removes the header information,\n",
    "    calculates and adds a date column (based on year and day), and the\n",
    "    average temperature (based on maxt and mint).\n",
    "    '''\n",
    "    import math\n",
    "\n",
    "    # these XYPairs are use when calculating Thermal Time \n",
    "    # and are specific to Wheat only\n",
    "    xp = [0, 26, 37]\n",
    "    fp = [0, 26, 0]\n",
    "    \n",
    "    lineNo = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            lineNo = lineNo + 1\n",
    "            if line.startswith('year'):\n",
    "                break;\n",
    "\n",
    "    # return the data using the starting line no (determined above)\n",
    "    # original column names=['year','day', 'radn', 'maxt', 'mint', 'rain']\n",
    "    metData = pd.read_table(filename, sep='\\s+', header=None, skiprows=lineNo+1,\n",
    "                            names=['year','dayofYear', 'radiation', 'maxTemp', 'minTemp', 'rain'])\n",
    "    \n",
    "    # add the calculated columns\n",
    "    metData['runDate'] = pd.to_datetime(metData['year'].astype(str) + \" \" + metData['dayofYear'].astype(str), format=\"%Y %j\")\n",
    "\n",
    "    #filter this file based on the dates we are working with\n",
    "    metData = metData[(metData['runDate'] >= startDate) & (metData['runDate'] <= endDate)] \n",
    "        \n",
    "    # this may need to be the thermal time, not just average temp\n",
    "    metData['avgTemp'] = (metData['maxTemp'] + metData['minTemp']) / 2\n",
    "\n",
    "    # calculate the Apsim Thermal Time\n",
    "    metData['ApsimTT'] = metData.apply(lambda x: linint_3hrly_Temperature(x['maxTemp'], x['minTemp'], xp, fp), axis=1)\n",
    "    \n",
    "    #convert the radiation from MJ/m2/day to Photosynthetically active radiation (PAR)\n",
    "    metData['PARIO'] = metData['radiation'] * 0.47\n",
    "\n",
    "    #convert the measurement unit for the radiation from MJ/m2/day to J/m2/day\n",
    "    metData['radnJ'] = metData['radiation'] * 1000000\n",
    "\n",
    "    metData['PQ'] = metData['PARIO'] / metData['avgTemp']\n",
    "\n",
    "    # calculation the day length\n",
    "    radians = math.pi/180\n",
    "    lambdaRadians = float(latitude) * radians\n",
    "\n",
    "    sinLAT = math.sin(lambdaRadians)\n",
    "    cosLAT = math.cos(lambdaRadians)\n",
    "    sinDMC = math.sin(radians * 23.45)\n",
    "\n",
    "    #print(\"radians: \", radians)\n",
    "    #print(\"lambdaRadians: \", lambdaRadians)\n",
    "    #print(\"sinLAT: \", sinLAT)\n",
    "    #print(\"cosLAT: \", cosLAT)\n",
    "    #print(\"sinDMC: \", sinDMC)    \n",
    "    \n",
    "    metData['sinDEC'] = -sinDMC * np.cos(2 * math.pi * (metData['dayofYear'] + 10) / 365)\n",
    "    metData['cosDEC'] = np.sqrt(1 - (metData['sinDEC'] * metData['sinDEC']))\n",
    "    metData['a'] = sinLAT * metData['sinDEC']\n",
    "    metData['b'] = cosLAT * metData['cosDEC']\n",
    "\n",
    "    metData['daylength'] = 12 * (1 + (2 / math.pi) * np.arcsin(metData['a']/metData['b']))\n",
    "\n",
    "    # calculate the Fraction Disfused Radiation (FDR)\n",
    "    metData['hour'] = np.mod(metData['dayofYear'], 1) * 24\n",
    "    metData['sinB'] = metData['a'] + metData['b'] * np.cos(2 * math.pi * (metData['hour'] - 12) / 24)\n",
    "    metData['SC'] = 1367 * (1 + 0.033 * np.cos(2 * math.pi * (metData['dayofYear'] - 10) / 365))\n",
    "    metData['sinINT'] = metData['a'] * metData['daylength'] + (24 * metData['b'] / math.pi) * \\\n",
    "                        np.cos((math.pi / 2) * ((metData['daylength'] / 12) - 1))\n",
    "\n",
    "    metData['Ta'] = metData['radnJ'] / (metData['sinINT'] * 3600 * metData['SC'])\n",
    "    metData['FDR'] = metData['Ta'] * -1.4545 + 1.2182\n",
    "\n",
    "    # calculate the Evapotranspiration\n",
    "    metData['vpsl'] = 238.102 * 17.32491 * ((metData['minTemp'] + metData['maxTemp']) /2) / \\\n",
    "                      (((metData['minTemp'] + metData['maxTemp']) / 2) + 238.102) ** 2\n",
    "    metData['ETpt'] = 1.26 * (metData['radnJ']  * (metData['vpsl'] / (metData['vpsl'] + 0.067))) / 2454000\n",
    "\n",
    "    \n",
    "    # sort the columns to be a little more logical\n",
    "    #cols=['year', 'dayofYear', 'runDate', 'dayLength', 'maxTemp', 'minTemp', 'avgTemp', 'ApsimTT', 'rain', \\\n",
    "    #      'PARIO', 'fracDiffusedRadn', 'vpsl', 'ETpt']\n",
    "    #metData = metData[cols]    \n",
    "    \n",
    "    return metData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weather_details(filename, latitude, startDate, endDate):\n",
    "    '''\n",
    "    Retrieves the weather data for the location (long,lat) specified in the dbname,\n",
    "    formats the data, and returns a dataframe\n",
    "    '''\n",
    "\n",
    "    fullfilename = metfile_sourcedir + \"/c_\" + filename + \".met\"\n",
    "    dfWeather = read_ApsimWeather(fullfilename, latitude, startDate, endDate)\n",
    "\n",
    "    return dfWeather\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data\n",
    "\n",
    "The following processes a single database file, collating it with the corresponding weather data.  \n",
    "\n",
    "##### NOTE:  dbname is defined at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"processing file: \", dbname)\n",
    "print(\"started at \", datetime.datetime.now())\n",
    "filename, longitude, latitude = get_filename(dbname)\n",
    "\n",
    "print(\"filename: \", filename)\n",
    "print(\"latitude: \", latitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the Simulation Details from the DB._Sumulation table\n",
    "dfSim = get_simulation_details(dbname) \n",
    "print(dfSim.shape)\n",
    "print(dfSim.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dfSim['variety'].unique()\n",
    "print(sorted(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variety, sowdate = get_variety_sowdate_for_location(longitude, latitude)\n",
    "print(\"variety: \", variety, \" - sowdate: \", sowdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variety, sowdate = get_variety_sowdate_for_location(145.00, -41.35)\n",
    "print(\"variety: \", variety, \" - sowdate: \", sowdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simIdStr = get_variety_SimID(dfSim, variety, sowdate)\n",
    "simIdStr\n",
    "\n",
    "#dfSimVar = dfSim[(dfSim['variety'] == variety & dfSim['sowdate'] == sowdate)]\n",
    "#dfSimVar = dfSim[(dfSim['variety'] == variety) & (dfSim['sowdate'] == sowdate)]\n",
    "#dfSimVar\n",
    "#print(dfSimVar.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrieve the Details from the DB.Report table\n",
    "dfReport = get_report_details(dbname, simIdStr, startDate, endDate)\n",
    "print(dfReport.shape)\n",
    "print(dfReport.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine the data with the Simulation details, so that we can get the sow date\n",
    "# and filter it again\n",
    "dfCombined = dfReport.merge(dfSim, on=\"SimID\", how='left')\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a sowing date (with current year)\n",
    "dfCombined['sowingdate'] = dfCombined['sowdate'] + '-' + dfCombined['runDate'].dt.year.map(str)\n",
    "dfCombined['sowingdate'] = pd.to_datetime(dfCombined['sowingdate'], format=\"%d-%b-%Y\")\n",
    "dfCombined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter the data from the Report details that we are not going to be looking at\n",
    "# ie, any data prior to our sow date for each year (should reduce size of data considerably)\n",
    "dfCombined = dfCombined[(dfCombined['runDate'] >= dfCombined['sowingdate'])] \n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#re-order and filter columns\n",
    "cols = ['SimID', 'long', 'lat', 'variety', 'sowdate', 'sowingdate', 'runDate', 'LAI', 'Biomass', 'Yield', \\\n",
    "        'ZadokStage', 'WSDR']\n",
    "dfCombined = dfCombined[cols] \n",
    "dfCombined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrieve the weather data from the weather '.met' file\n",
    "dfWeather = get_weather_details(filename, latitude, startDate, endDate)\n",
    "print(dfWeather.shape)\n",
    "print(dfWeather.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine the report data with the weather data\n",
    "dfCombined = dfCombined.merge(dfWeather, on='runDate', how='left')\n",
    "dfCombined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this will be part of the get_weather_details functionality, but is commented out so that I can check things\n",
    "#cols=['year', 'dayofYear', 'runDate', 'daylength', 'maxTemp', 'minTemp', 'avgTemp', 'ApsimTT', 'rain', \\\n",
    "#      'PARIO', 'PQ', 'FDR', 'vpsl', 'ETpt']\n",
    "#dfWeather = dfWeather[cols] \n",
    "outfilename = apsim_outfiledir + \"/\" + filename + \"_weather.csv\"\n",
    "dfWeather.to_csv(outfilename, encoding='utf-8', index=False)\n",
    "#dfWeather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create bins for the phases\n",
    "bins = [0, 7, 10, 31, 39, 65, 71, 87, 89, 90]\n",
    "group_names = ['01_Germinating', '02_Emerging', '03_Vegetative', '04_StemElongation',\n",
    "               '05_EarlyReproductive', '06_GrainSet', '07_GrainFilling', '08_Maturing', '09_Ripening']\n",
    "dfCombined['phases'] = pd.cut(dfCombined['ZadokStage'], bins, labels=group_names)\n",
    "dfCombined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the cumulative values that are for each season(year/sowing date)\n",
    "dfCombined['cumAvgTemp'] = dfCombined.groupby(by=['SimID','sowingdate'])['avgTemp'].cumsum()\n",
    "dfCombined['cumApsimTT'] = dfCombined.groupby(by=['SimID','sowingdate'])['ApsimTT'].cumsum()\n",
    "dfCombined['cumRain'] = dfCombined.groupby(by=['SimID','sowingdate'])['rain'].cumsum()\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the cumulative calculations for each phase\n",
    "dfCombined['cumPhaseAvgTemp'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['avgTemp'].cumsum()\n",
    "dfCombined['cumPhaseApsimTT'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['ApsimTT'].cumsum()\n",
    "dfCombined['cumPhaseRain'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['rain'].cumsum()\n",
    "dfCombined['cumPhaseETpt'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['ETpt'].cumsum()\n",
    "dfCombined['cumPhasePARIO'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['PARIO'].cumsum()\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is so that I can check the column Names and order\n",
    "#cols = dfCombined.columns.values.tolist()\n",
    "#print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==============================================================\n",
    "# NEED TO CONVERT THE phases column to string so that I can add stage 10\n",
    "# currently it is classified as catagorical data\n",
    "#dfCombined['phases'].dtypes\n",
    "#==============================================================\n",
    "dfCombined['phases'] = dfCombined['phases'].astype(str)\n",
    "dfCombined['phases'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update all record where Zadok = 90 and cumPhaseApsimTT > 300 to be '10_Harvest'\n",
    "dfCombined.loc[(dfCombined['ZadokStage'] == 90) & (dfCombined['cumPhaseApsimTT'] >= 300 ),'phases'] = '10_Harvest'\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only need to keep first '10_Harvest' record\n",
    "# so need to flag records so that we can filter out the ones that we don't want\n",
    "dfCombined.loc[dfCombined.groupby(['SimID','sowingdate','phases'])['cumPhaseApsimTT'].idxmin(),'firstHarvest'] = 1\n",
    "dfCombined.loc[(dfCombined['phases'] != '10_Harvest' ),'firstHarvest'] = 1\n",
    "dfCombined['firstHarvest'] = dfCombined.firstHarvest.fillna(0).astype(int)\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter the records that we need\n",
    "dfCombined = dfCombined[(dfCombined['firstHarvest'] == 1)]\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output the data set - for testing only - not required in '.py' script\n",
    "subData = dfCombined.loc[dfCombined['SimID'].isin([2,3,4])]\n",
    "outfilename = apsim_outfiledir + \"/filtered_\" + filename + \".csv\"\n",
    "subData.to_csv(outfilename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Need to generate the summary report: \n",
    "This section builds a summary dataframe based on the information calculated above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these are the figures for the season\n",
    "dfSummary = dfCombined.groupby(by=['SimID','sowingdate','phases'])['cumAvgTemp'].max().reset_index()\n",
    "dfSummary.columns = ['SimID', 'sowingdate', 'phases', 'season_cumAvgTemp']\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID','sowingdate','phases'])['cumApsimTT'].max().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'season_cumApsimTT']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID','sowingdate','phases'])['cumRain'].max().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'season_cumRain']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSummary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each phase, what is the start date, end date and number of days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#what are the start and end dates for the phase\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].min().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'startDate']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].max().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'endDate']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "#how many days in each of the phases\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'dayCount']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSummary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What Temperature information do we need for each phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#what is the minimimum temperature for the phase\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['minTemp'].mean().reset_index()\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "#dfSummary\n",
    "\n",
    "#what is the maximum temperature for the phase\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['maxTemp'].mean().reset_index()\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "#dfSummary\n",
    "\n",
    "\n",
    "#what is the average of average temp for the phase\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['avgTemp'].mean().reset_index()\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "# get the average temp value for the last day in each phase \n",
    "dfSum = dfCombined.groupby(by=['SimID','sowingdate','phases'])['cumPhaseAvgTemp'].last().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'cumAvgTemp']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "\n",
    "#what is the average of average ApsimTT for the phase\n",
    "dfSum = dfCombined.groupby(by=['SimID','sowingdate','phases'])['ApsimTT'].mean().reset_index()\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "# get the ApsimTT value for the last day in each phase \n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['cumPhaseApsimTT'].last().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'cumApsimTT']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSummary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now calculation the information for the phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what average (mean) values are required\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['WSDR'].mean().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'avgWSDR']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['PARIO'].mean().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'avgPARIO']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['FDR'].mean().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'avgFDR']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['PQ'].mean().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'avgPQ']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['daylength'].mean().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'avgDaylength']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "\n",
    "# what are the values for the last record (day) of each phase  \n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['cumPhaseRain'].last().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'cumRain']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['cumPhaseETpt'].last().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'cumETpt']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['cumPhasePARIO'].last().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'cumPARIO']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "\n",
    "# the following are measurments based on the crop outputs\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['Biomass'].last().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'Biomass']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['LAI'].last().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'LAI']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['Yield'].last().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'Yield']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following are for counting the number of days that fit a certain criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the counts of various miniumum temperatures\n",
    "dfSum = dfCombined[dfCombined['minTemp'] <= 0].groupby(by=['SimID','sowingdate','phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days<=0']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['minTemp'] <= -1].groupby(by=['SimID','sowingdate','phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days<=-1']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['minTemp'] <= -2].groupby(by=['SimID','sowingdate','phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days<=-2']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['minTemp'] <= -3].groupby(by=['SimID','sowingdate','phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days<=-3']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the counts of various maximum temperatures\n",
    "dfSum = dfCombined[dfCombined['maxTemp'] >= 30].groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days>=30']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['maxTemp'] >= 32].groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days>=32']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['maxTemp'] >= 34].groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days>=34']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['maxTemp'] >= 36].groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days>=36']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['maxTemp'] >= 38].groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days>=38']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['maxTemp'] >= 40].groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days>=40']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSummary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add back to Simulation details to get longitude, latitude and cultivar details and output the data to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfSummary = dfSummary.merge(dfSim, on=\"SimID\", how='left')\n",
    "dfSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = dfSummary.columns.values.tolist()\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now re-sort the columns so that the order is more logical\n",
    "cols = ['SimID', 'variety', 'long', 'lat', 'sowingdate', 'phases', \n",
    "        'season_cumAvgTemp', 'season_cumApsimTT', 'season_cumRain', 'startDate', 'endDate', \n",
    "        'dayCount', 'minTemp', 'maxTemp', 'avgTemp', 'ApsimTT', 'avgDaylength', \n",
    "        'cumAvgTemp', 'cumApsimTT', 'cumRain', 'avgWSDR', 'cumETpt', 'cumPARIO', \n",
    "        'avgPARIO', 'avgFDR', 'avgPQ', 'Biomass', 'LAI', 'Yield', \n",
    "        'days<=0', 'days<=-1', 'days<=-2', 'days<=-3', \n",
    "        'days>=30', 'days>=32', 'days>=34', 'days>=36', 'days>=38', 'days>=40']\n",
    "#cols\n",
    "dfSummary = dfSummary[cols]\n",
    "dfSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfilename = apsim_outfiledir + \"/filtered_\" + filename + \"_summary.csv\"\n",
    "dfSummary.to_csv(outfilename, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
