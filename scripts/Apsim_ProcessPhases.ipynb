{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Growth Phases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks at the SQLite Databases generated by Apsim X (Next Gen) for 109 Wheat varieties, 10 differing sow dates for  57,434 locations/sites across Australia.  \n",
    "Each database file covers one (1) site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the working directories\n",
    "apsim_sourcedir = \"/OSM/CBR/AG_WHEATTEMP/source\"\n",
    "apsim_outfiledir = \"/OSM/CBR/AG_WHEATTEMP/work/output\"\n",
    "metfile_sourcedir = \"/OSM/CBR/AG_WHEATTEMP/work/ApsimNG-test/APSIM_run/met\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       filename\n",
      "0  /OSM/CBR/AG_WHEATTEMP/source/113.60-28.30.db\n",
      "1  /OSM/CBR/AG_WHEATTEMP/source/113.70-28.45.db\n",
      "2  /OSM/CBR/AG_WHEATTEMP/source/113.70-28.50.db\n",
      "3  /OSM/CBR/AG_WHEATTEMP/source/113.75-28.45.db\n",
      "4  /OSM/CBR/AG_WHEATTEMP/source/113.75-28.50.db\n",
      "/OSM/CBR/AG_WHEATTEMP/source/113.60-28.30.db\n"
     ]
    }
   ],
   "source": [
    "dbfile_df = pd.DataFrame(columns=['filename'])\n",
    "dbfile_df.filename = sorted(apsim_sourcedir+'/'+f for f in os.listdir(apsim_sourcedir) if f.endswith('.db'))\n",
    "print(dbfile_df.head())\n",
    "dbname = dbfile_df.filename[0]\n",
    "print(dbname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_day_length(lat, doy, radn):\n",
    "    '''\n",
    "    Calculates the day length based on the latitude and the day of the year\n",
    "    \n",
    "    sample usage:\n",
    "    >>> daylength = calc_day_length(-27.55, 1)\n",
    "    13.71\n",
    "    >>> daylength = calc_day_length(-27.55, 2)\n",
    "    13.7\n",
    "    >>> daylength = calc_day_length(-27.55, 3)\n",
    "    13.69\n",
    "    '''\n",
    "    \n",
    "    import math\n",
    "    \n",
    "    if lat == 0:\n",
    "        print(\"The latitude must be greater than zero.\")\n",
    "        return 0\n",
    "    \n",
    "    if (doy <= 0 or doy > 366):\n",
    "        print(\"The day of year (doy) must be a valid day of the year, between 1 and 365.\")\n",
    "        return 0\n",
    "    \n",
    "    #latitude (lambda) in radians\n",
    "    radians = math.pi/180\n",
    "    latlambda = lat * radians\n",
    "    radnJ = radn * 1000000\n",
    "    \n",
    "    sinLAT = math.sin(latlambda)\n",
    "    cosLAT = math.cos(latlambda)\n",
    "    sinDMC = radians * 23.45\n",
    "    sinDEC = -sinDMC * math.cos(2 * math.pi * (doy + 10) / 365)\n",
    "    cosDEC = math.sqrt(1 - (sinDEC * sinDEC))\n",
    "    a = sinLAT * sinDEC\n",
    "    b = cosLAT * cosDEC\n",
    "\n",
    "    daylength = 12 * (1 + (2 / math.pi) * math.asin(a/b))\n",
    "    \n",
    "    hour = math.mod(doy, 1) * 24\n",
    "    sinB = a + b * math.cos(2 * math.pi * (hour - 12) / 24)\n",
    "    SC = 1367 * (1 + 0.033 * math.cos(2 * math.pi * (doy - 10) / 365))\n",
    "    sinINT = a * day_length + (24 * b / math.pi) * math.cos((math.pi / 2) * ((daylength / 12) - 1))\n",
    "    \n",
    "    Ta = radnJ / (sinINT * 3600 * SC)\n",
    "    fracDiffusedRadn = Ta * -1.6 +1.32\n",
    "    \n",
    "    #print(round(latlambda,4), \", \", round(sindelta,2), \",\", round(cosdelta,2), \",\", \\\n",
    "    #      round(sinlambda,2), \", \", round(coslambda,2), \", \", round(a, 2), \", \", \\\n",
    "    #      round(b, 2), \", \", round(day_length, 2))\n",
    "          \n",
    "    return daylength, fracDiffusedRadn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_ApsimWeather(filename, lat):\n",
    "    '''\n",
    "    Reads an apsim weather ('.met') file, removes the header information,\n",
    "    calculates and adds a date column (based on year and day), and the\n",
    "    average temperature (based on maxt and mint).\n",
    "    '''\n",
    "    import math\n",
    "\n",
    "    \n",
    "    lineNo = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            lineNo = lineNo + 1\n",
    "            if line.startswith('year'):\n",
    "                break;\n",
    "\n",
    "    # return the data using the starting line no (determined above)\n",
    "    # original column names=['year','day', 'radn', 'maxt', 'mint', 'rain']\n",
    "    metData = pd.read_table(filename, sep='\\s+', header=None, skiprows=lineNo+1,\n",
    "                            names=['year','dayofYear', 'radiation', 'maxTemp', 'minTemp', 'rain'])\n",
    "\n",
    "    # add the calculated columns\n",
    "    metData['runDate'] = pd.to_datetime(metData['year'].astype(str) + \" \" + metData['dayofYear'].astype(str), format=\"%Y %j\")\n",
    "\n",
    "    # this may need to be the thermal time, not just average temp\n",
    "    metData['avgTemp'] = (metData['maxTemp'] + metData['minTemp']) / 2\n",
    "\n",
    "    #convert the radiation from MJ/m2/day to Photosynthetically active radiation (PAR)\n",
    "    metData['PARIO'] = metData['radiation'] * 0.47\n",
    "    \n",
    "    #convert the measurement unit for the radiation from MJ/m2/day to J/m2/day\n",
    "    metData['radnJ'] = metData['radiation'] * 1000000\n",
    "\n",
    "    \n",
    "    # calculation the day length\n",
    "    radians = math.pi/180\n",
    "    latlambda = lat * radians\n",
    "    \n",
    "    sinLAT = math.sin(latlambda)\n",
    "    cosLAT = math.cos(latlambda)\n",
    "    sinDMC = radians * 23.45\n",
    "    \n",
    "    metData['sinDEC'] = -sinDMC * math.cos(2 * math.pi * (metData['dayofYear'] + 10) / 365)\n",
    "    metData['cosDEC'] = math.sqrt(1 - (metData['sinDEC'] * metData['sinDEC']))\n",
    "    metData['a'] = sinLAT * metData['sinDEC']\n",
    "    metData['b'] = cosLAT * metData['cosDEC']\n",
    "\n",
    "    metData['daylength'] = 12 * (1 + (2 / math.pi) * math.asin(metData['a']/metData['b']))\n",
    "    \n",
    "    # calculate the Fraction Disfused Radiation (FDR)\n",
    "    metData['hour'] = math.mod(metData['dayofYear'], 1) * 24\n",
    "    metData['sinB'] = metData['a'] + metData['b'] * math.cos(2 * math.pi * (metData['hour'] - 12) / 24)\n",
    "    metData['SC'] = 1367 * (1 + 0.033 * math.cos(2 * math.pi * (metData['dayofYear'] - 10) / 365))\n",
    "    metData['sinINT'] = metData['a'] * metData['daylength'] + (24 * metData['b'] / math.pi) * \\\n",
    "                        math.cos((math.pi / 2) * ((metData['daylength'] / 12) - 1))\n",
    "    \n",
    "    metData['Ta'] = radnJ / (metData['sinINT'] * 3600 * metData['SC'])\n",
    "    metData['fracDiffusedRadn'] = metData['Ta'] * -1.6 +1.32\n",
    "        \n",
    "    # calculate the Evapotranspiration\n",
    "    metData['vpsl'] = 238.102 * 17.32491 * ((metData['minTemp'] + metData['maxTemp']) /2) / \\\n",
    "                      (((metData['minTemp'] + metData['maxTemp']) / 2) + 238.102) ** 2\n",
    "    metData['ETpt'] = 1.26 * (metData['radnJ']  * (metData['vpsl'] / (metData['vpsl'] + 0.067))) / 2454000\n",
    "        \n",
    "    \n",
    "    # sort the columns to be a little more logical\n",
    "    cols=['year', 'dayofYear', 'runDate', 'dayLength', 'maxTemp', 'minTemp', 'avgTemp', 'rain', 'radiation', \\\n",
    "          'PARIO', 'fracDiffusedRadn', 'ETpt']\n",
    "    metData = metData[cols]\n",
    "\n",
    "    return metData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_simulation_details(dbname):\n",
    "    '''\n",
    "    Opens the specified SQL Database and extracts the 'Name' details from the Simulation\n",
    "    Table, and splits it to Simulation ID, Longitude, Latitude, Variety, SowDate, and\n",
    "    returns ad dataframe.\n",
    "    '''\n",
    "\n",
    "    # connect to the Database\n",
    "    con = sqlite3.connect(dbname)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # get contents of the _Simulation Table\n",
    "    strSql = \"SELECT ID as SimulationID, Name FROM _Simulations\"\n",
    "    dfSim = pd.read_sql_query(strSql, con, index_col = 'SimulationID')\n",
    "\n",
    "    # split the 'Name' field into long, lat, variety and sowdate columns\n",
    "    dfSim[['long','lat','variety','sowdate']] = \\\n",
    "    dfSim['Name'].str.extract(\"^(?P<long>\\d+)_(?P<lat>-?\\d+)_(?P<variety>\\S+)_(?P<sowdate>\\d+-\\S+)$\", expand=True)\n",
    "\n",
    "    # format the columns\n",
    "    pd.options.display.float_format = '{:,.2f}'.format\n",
    "    dfSim['long'] = dfSim['long'].astype(float) / 100\n",
    "    dfSim['lat'] = dfSim['lat'].astype(float) / 100\n",
    "\n",
    "    # create a SimId column (as the original SimulationID is now an index column)\n",
    "    dfSim['SimID'] = dfSim.index \n",
    "\n",
    "    return dfSim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_report_details(dbname):\n",
    "    '''\n",
    "    Opens the specified SQL Database and extracts the details from the Report\n",
    "    Table, formats the columns correctly and returns a dataframe\n",
    "    '''\n",
    "\n",
    "    # connect to the Database\n",
    "    con = sqlite3.connect(dbname)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # get contents of the Report Table\n",
    "    #strSql = \"SELECT SimulationID, substr([Clock.Today], 1, 10) as runDate, \\\n",
    "    #      [Wheat.Leaf.LAI] as LAI, [Wheat.AboveGround.Wt] as Biomass, \\\n",
    "    #      [Wheat.Grain.Wt] as Yield, [Wheat.Phenology.Zadok.Stage] as ZadokStage, \\\n",
    "    #      [Wheat.WaterSupplyDemandRatio] as WaterSupplyDemandRatio, \\\n",
    "    #      [Wheat.Root.NUptake] as RootNUptake, [Wheat.Leaf.Fn] as LeafFn \\\n",
    "    #      FROM Report \\\n",
    "    #      ORDER BY SimulationID, runDate\"\n",
    "    \n",
    "    #Need to exclude consider CUTOFFS\n",
    "\n",
    "    #do not need all of the columns, will cut this down from the get go\n",
    "    strSql = \"SELECT SimulationID, substr([Clock.Today], 1, 10) as runDate, \\\n",
    "          [Wheat.Leaf.LAI] as LAI, [Wheat.AboveGround.Wt] as Biomass, \\\n",
    "          [Wheat.Grain.Wt] as Yield, [Wheat.Phenology.Zadok.Stage] as ZadokStage, \\\n",
    "          [Wheat.WaterSupplyDemandRatio] as WaterSupplyDemandRatio \\\n",
    "          FROM Report \\\n",
    "          ORDER BY SimulationID, runDate\"    \n",
    "    #print(datetime.datetime.now())\n",
    "    dfReport = pd.read_sql_query(strSql, con, index_col=\"SimulationID\" )\n",
    "    #print(datetime.datetime.now())\n",
    "\n",
    "    # format the date columns\n",
    "    dfReport['runDate'] = pd.to_datetime(dfReport['runDate'], format=\"%Y-%m-%d\")\n",
    "\n",
    "    # create the SimId column\n",
    "    dfReport['SimID'] = dfReport.index\n",
    "\n",
    "    return dfReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filename(dbname):\n",
    "    '''\n",
    "    Takes the full path and filename for the database file, and creates the filename\n",
    "    that is used for the weather file, and to save the output.\n",
    "\n",
    "    Note:  cannot use the db filename as it doesn't have the long & lat that we require\n",
    "           need to manipulate the filename to add the underscrore '_' char\n",
    "           ONLY need to allow for negative (south) latitudes\n",
    "    '''\n",
    "    filename = os.path.basename(dbname)\n",
    "    filename = os.path.splitext(filename)[0]\n",
    "    nameparts = filename.split('-')\n",
    "    filename = nameparts[0] + '_-' + nameparts[1]\n",
    "    lat = '-' + nameparts[1]\n",
    "\n",
    "    return filename, lat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weather_details(filename, latitude):\n",
    "    '''\n",
    "    Retrieves the weather data for the location (long,lat) specified in the dbname,\n",
    "    formats the data, and returns a dataframe\n",
    "    '''\n",
    "\n",
    "    fullfilename = metfile_sourcedir + \"/c_\" + filename + \".met\"\n",
    "    dfWeather = read_ApsimWeather(fullfilename, latitude)\n",
    "\n",
    "    return dfWeather\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data\n",
    "The following forms a single function:  def process_Apsim_dbfile(dbname):  \n",
    "#### NOTE:  dbname is defined at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file:  /OSM/CBR/AG_WHEATTEMP/source/113.60-28.30.db\n",
      "started at  2018-07-27 10:42:26.522674\n",
      "(1071, 6)\n",
      "                                      Name   long    lat     variety sowdate  \\\n",
      "SimulationID                                                                   \n",
      "1                 11360_-2830_young_29-jul 113.60 -28.30       young  29-jul   \n",
      "2             11360_-2830_agt_katana_1-apr 113.60 -28.30  agt_katana   1-apr   \n",
      "3             11360_-2830_agt_scythe_1-apr 113.60 -28.30  agt_scythe   1-apr   \n",
      "4               11360_-2830_annuello_1-apr 113.60 -28.30    annuello   1-apr   \n",
      "5                 11360_-2830_aroona_1-apr 113.60 -28.30      aroona   1-apr   \n",
      "\n",
      "              SimID  \n",
      "SimulationID         \n",
      "1                 1  \n",
      "2                 2  \n",
      "3                 3  \n",
      "4                 4  \n",
      "5                 5  \n"
     ]
    }
   ],
   "source": [
    "print(\"processing file: \", dbname)\n",
    "print(\"started at \", datetime.datetime.now())\n",
    "\n",
    "# retrieve the Simulation Details from the DB._Sumulation table\n",
    "dfSim = get_simulation_details(dbname) \n",
    "print(dfSim.shape)\n",
    "print(dfSim.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-772e47616a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# retrieve the weather data from the weather '.met' file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdbname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdfWeather\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_weather_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfWeather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfWeather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# retrieve the weather data from the weather '.met' file\n",
    "filename, latitude = get_filename(dbname)\n",
    "dfWeather = get_weather_details(filename, latitude)\n",
    "print(dfWeather.shape)\n",
    "print(dfWeather.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the Details from the DB.Report table\n",
    "dfReport = get_report_details(dbname)\n",
    "print(dfReport.shape)\n",
    "print(dfReport.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the report data with the weather data\n",
    "dfCombined = dfReport.merge(dfWeather, on='runDate', how='left')\n",
    "dfCombined\n",
    "# filter the data based on the information we want\n",
    "#filterCols = ['SimID', 'runDate', 'ZadokStage', 'avgTemp']\n",
    "#dfSubData = dfCombined[filterCols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the data with the Simulation details, so that we can get the sow date\n",
    "# and filter it again\n",
    "dfCombined = dfCombined.merge(dfSim, on=\"SimID\", how='left')\n",
    "#filterCols = ['SimID', 'runDate', 'ZadokStage', 'avgTemp', 'sowdate']\n",
    "#dfSubData = dfSubData[filterCols]\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add extra (weather) columns into this\n",
    "filterCols = ['SimID', 'year', 'dayofYear', 'runDate', 'LAI', 'Biomass', 'Yield', \n",
    "              'ZadokStage', 'WaterSupplyDemandRatio',  'minTemp', 'maxTemp', \n",
    "              'avgTemp', 'rain', 'radiation', 'long', 'lat', 'variety', 'sowdate']\n",
    "dfSubData = dfCombined[filterCols]\n",
    "dfSubData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#??? \n",
    "#do we need to re-order the data here so that it is long, lat, variety, sowdate, runDate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a sowing date (with current year)\n",
    "dfSubData['sowingdate'] = dfSubData['sowdate'] + '-' + dfSubData['runDate'].dt.year.map(str)\n",
    "dfSubData['sowingdate'] = pd.to_datetime(dfSubData['sowingdate'], format=\"%d-%b-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now calculate the cumulative temp info for each simulation \n",
    "# 90 is maturity (start of ripening stage)\n",
    "#& (dfSubData['ZadokStage'] <= 90)\n",
    "\n",
    "dfSubData['tempavgTemp'] = dfSubData['avgTemp'].where((dfSubData['runDate'] >= dfSubData['sowingdate']) \n",
    "                                                      & (dfSubData['ZadokStage'] > 0)\n",
    "                                                      & (dfSubData['ZadokStage'] <= 90), 0)\n",
    "dfSubData['TTAfterSowing'] = dfSubData.groupby(by=['SimID','sowingdate'])['tempavgTemp'].cumsum()\n",
    "dfSubData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter the data on the tempavgTemp column\n",
    "newData = dfSubData[dfSubData['tempavgTemp'] > 0]\n",
    "#newData1 = newData.groupby(['SimID','sowdate'])['TTAfterSowing'].max().reset_index()\n",
    "newData1 = newData.groupby(['SimID','sowingdate'])['TTAfterSowing'].max().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#newData2 = newData1.groupby(['SimID','sowdate'])['TTAfterSowing'].mean().reset_index()\n",
    "newData2 = newData1.groupby(['SimID','sowingdate'])['TTAfterSowing'].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create bins for the phases\n",
    "bins = [0, 7, 10, 31, 39, 71, 87, 90, 120]\n",
    "group_names = ['01_Germinating', '02_Emerging', '03_Vegetative', '04_StemElongation',\n",
    "               '05_GrainSet', '06_GrainFilling', '07_Maturing', '08_Ripening']\n",
    "dfSubData['phases'] = pd.cut(dfSubData['ZadokStage'], bins, labels=group_names)\n",
    "dfSubData\n",
    "\n",
    "#might need to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Need to determine the phases: \n",
    "•\tlength (no of days in phase), minTemp, maxTemp, and avgTemp,  \n",
    "•\tthe cumulativeAvgTemp at the end of each phase, (needs to be called TTAfterSowing)  \n",
    "•\tthe counts for number of day where temperatures are below or above specified values (refer to SIP_Temp discussion.docs for further details)  \n",
    "•\tthe average and cumulative rainfall   \n",
    "•\taverage radiation, cumulative radiation  \n",
    "•\taverage watersupplydemandratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# eliminate those records where the phase is Nan\n",
    "#dfSubData.dropna(subset=['phases'], inplace=True)\n",
    "#dfSubData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a function to get the stats for group\n",
    "def get_stats(group):\n",
    "    return {'min': group.min(), 'max': group.max(), 'mean': group.mean(), 'count': group.count()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#should I add a column that can be a concatinated key\n",
    "dfSubData['SimIdSowingdatePhase'] = dfSubData['SimId'].map(str) + \\ \n",
    "    dfSubData['sowingdate'].map(str) + dfSubData['phases']\n",
    "\n",
    "#apply the get_stats function to each phase bin\n",
    "dfSubData['ZadokStage'].groupby(dfSubData['SimIdSowingdatePhase']).apply(get_stats).unstack()\n",
    "dfSubData,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many days in each of the phases\n",
    "newData1.groupby(['SimIdSowingdatePhase'].count().reset_index()\n",
    "\n",
    "#what is the minimimum temperature for the phase\n",
    "newData1.groupby(['SimIdSowingdatePhase'])['minTemp'].min().reset_index()\n",
    "#what is the maximum temperature for the phase\n",
    "newData1.groupby(['SimIdSowingdatePhase'])['maxTemp'].max().reset_index()\n",
    "\n",
    " newData1.groupby(['SimIdSowingdatePhase'])['biomass'].max().reset_index()\n",
    "\n",
    "#what is the average of average temp for the phase\n",
    "newData1.groupby(['SimIdSowingdatePhase'])['avgTemp'].mean().reset_index()\n",
    "\n",
    "#what is the average of average daily radiation for the phase\n",
    "#newData1.groupby(['SimIdSowingdatePhase'])['radn'].mean().reset_index()\n",
    "\n",
    "#what is the cumulative rainfall for each phase\n",
    "newData1.groupby(by=['SimIdSowingdatePhase'])['rain'].cumsum()\n",
    "\n",
    "newData1.groupby(by=['SimIdSowingdatePhase'])['ETpt'].cumsum()\n",
    "\n",
    "newData1.groupby(by=['SimIdSowingdatePhase'])['PARIO'].mean().reset_index()\n",
    "newData1.groupby(by=['SimIdSowingdatePhase'])['PARIO'].cumsum()\n",
    "\n",
    "newData1.groupby(by=['SimIdSowingdatePhase'])['PQDay'].mean.reset_index()\n",
    "newData1.groupby(by=['SimIdSowingdatePhase'])['daylengh'].mean.reset_index()\n",
    "\n",
    "#need to get the values for the last day in each phase:\n",
    "startdate, enddate, DAS, LAI, Biomass, Yield\n",
    "                \n",
    "                 \n",
    "#what is the average of average watersupplydemandratio for the phase\n",
    "newData1.groupby(['SimIdSowingdatePhase'])['watersupplydemandratio'].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the counts of various miniumum temperatures\n",
    "newData1[newData1['minTemp'] <= 0].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['minTemp'] <= -1].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['minTemp'] <= -2].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['minTemp'] <= -3].groupby['SimIdSowingdatePhase'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the counts of various maximum temperatures\n",
    "newData1[newData1['maxTemp'] >= 30].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['maxTemp'] >= 32].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['maxTemp'] >= 34].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['maxTemp'] >= 36].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['maxTemp'] >= 38].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['maxTemp'] >= 40].groupby['SimIdSowingdatePhase'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to add back in the longitude, latitude, variety from dfSim\n",
    "newData2 = newData2.merge(dfSim, on=['SimID', 'sowdate'], how='left')\n",
    "filterCols = ['SimID', 'long', 'lat', 'variety', 'sowdate', 'TTAfterSowing']\n",
    "newData2 = newData2[filterCols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfilename = apsim_outfiledir + \"/\" + filename + \"_zadok.csv\"\n",
    "newData2.to_csv(outfilename, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
