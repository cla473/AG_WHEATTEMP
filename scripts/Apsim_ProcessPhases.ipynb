{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Growth Phases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks at the SQLite Databases generated by Apsim X (Next Gen) for 109 Wheat varieties, 10 differing sow dates for  57,434 locations/sites across Australia.  \n",
    "Each database file covers one (1) site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the working directories\n",
    "apsim_sourcedir = \"/OSM/CBR/AG_WHEATTEMP/source\"\n",
    "apsim_outfiledir = \"/OSM/CBR/AG_WHEATTEMP/work/output\"\n",
    "metfile_sourcedir = \"/OSM/CBR/AG_WHEATTEMP/work/ApsimNG-test/APSIM_run/met\"\n",
    "\n",
    "startDate = pd.to_datetime(\"1957-01-01\", format=\"%Y-%m-%d\")\n",
    "endDate = pd.to_datetime(\"2016-12-31\", format=\"%Y-%m-%d\")\n",
    "varietylist = ['agt_katana','agt_scythe','axe','baxter','bolac','ega_gregory',\n",
    "               'ega_wylie','h46','h45','janz','lancer','mace','sentinel','sunbri',\n",
    "               'sunstate','sunvale','ventura','westonia','yitpi']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile_df = pd.DataFrame(columns=['filename'])\n",
    "dbfile_df.filename = sorted(apsim_sourcedir+'/'+f for f in os.listdir(apsim_sourcedir) if f.endswith('.db'))\n",
    "print(dbfile_df.head())\n",
    "dbname = dbfile_df.filename[4]\n",
    "print(dbname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these are required for calculations of thermal time\n",
    "num3hr = int(24 / 3)\n",
    "#print(\"num3hr: \", num3hr)    \n",
    "t_range_fract = []\n",
    "\n",
    "# pre calculate t_range_fract for speed reasons\n",
    "for period in range(num3hr):\n",
    "    calcValue = 0.92105 \\\n",
    "                + 0.1140 * period \\\n",
    "                - 0.0703 * math.pow(period, 2) \\\n",
    "                + 0.0053 * math.pow(period, 3)\n",
    "    t_range_fract.append(calcValue)\n",
    "\n",
    "#print(\"t_range_fract: \", t_range_fract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_simulation_details(dbname):\n",
    "    '''\n",
    "    Opens the specified SQL Database and extracts the 'Name' details from the Simulation\n",
    "    Table, and splits it to Simulation ID, Longitude, Latitude, Variety, SowDate, and\n",
    "    returns ad dataframe.\n",
    "    '''\n",
    "\n",
    "    # connect to the Database\n",
    "    con = sqlite3.connect(dbname)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # get contents of the _Simulation Table\n",
    "    strSql = \"SELECT ID as SimulationID, Name FROM _Simulations\"\n",
    "    dfSim = pd.read_sql_query(strSql, con, index_col = 'SimulationID')\n",
    "\n",
    "    # split the 'Name' field into long, lat, variety and sowdate columns\n",
    "    dfSim[['long','lat','variety','sowdate']] = \\\n",
    "    dfSim['Name'].str.extract(\"^(?P<long>\\d+)_(?P<lat>-?\\d+)_(?P<variety>\\S+)_(?P<sowdate>\\d+-\\S+)$\", expand=True)\n",
    "\n",
    "    # format the columns\n",
    "    pd.options.display.float_format = '{:,.2f}'.format\n",
    "    dfSim['long'] = dfSim['long'].astype(float) / 100\n",
    "    dfSim['lat'] = dfSim['lat'].astype(float) / 100\n",
    "\n",
    "    # create a SimId column (as the original SimulationID is now an index column)\n",
    "    dfSim['SimID'] = dfSim.index \n",
    "\n",
    "    return dfSim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_variety_SimIDs(dfSim, varieties):\n",
    "    '''\n",
    "    Creates a list of SimulationIDs based on a list of varieties\n",
    "    '''\n",
    "    \n",
    "    dfSimVar = dfSim[dfSim['variety'].isin(varieties)]\n",
    "    #print(dfSimVar.shape)\n",
    "    #dfSimVar\n",
    "\n",
    "    #now create a list of the SimId's\n",
    "    simIds = dfSimVar.index.tolist()\n",
    "    simIdStr = ', '.join(str(e) for e in simIds)\n",
    "    \n",
    "    return simIdStr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_report_details(dbname, simIdStr, startDate, endDate):\n",
    "    '''\n",
    "    Opens the specified SQL Database and extracts the details from the Report\n",
    "    Table, formats the columns correctly and returns a dataframe\n",
    "    '''\n",
    "\n",
    "    # connect to the Database\n",
    "    con = sqlite3.connect(dbname)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # get contents of the Report Table\n",
    "    #strSql = \"SELECT SimulationID, substr([Clock.Today], 1, 10) as runDate, \\\n",
    "    #      [Wheat.Leaf.LAI] as LAI, [Wheat.AboveGround.Wt] as Biomass, \\\n",
    "    #      [Wheat.Grain.Wt] as Yield, [Wheat.Phenology.Zadok.Stage] as ZadokStage, \\\n",
    "    #      [Wheat.WaterSupplyDemandRatio] as WaterSupplyDemandRatio, \\\n",
    "    #      [Wheat.Root.NUptake] as RootNUptake, [Wheat.Leaf.Fn] as LeafFn \\\n",
    "    #      FROM Report \\\n",
    "    #      ORDER BY SimulationID, runDate\"\n",
    "    \n",
    "    #Need to exclude consider CUTOFFS\n",
    "    #Need to use DISTINCT AS THERE SEEMS TO BE SOME DUPLICATIONS IN TO DATA\n",
    "\n",
    "    #do not need all of the columns, will cut this down from the get go\n",
    "    strSql = \"SELECT DISTINCT SimulationID, substr([Clock.Today], 1, 10) as runDate, \\\n",
    "          [Wheat.Leaf.LAI] as LAI, [Wheat.AboveGround.Wt] as Biomass, \\\n",
    "          [Wheat.Grain.Wt] as Yield, [Wheat.Phenology.Zadok.Stage] as ZadokStage, \\\n",
    "          [Wheat.WaterSupplyDemandRatio] as WSDR \\\n",
    "          FROM Report \\\n",
    "          WHERE SimulationID IN (\" + simIdStr + \") \\\n",
    "            AND [Wheat.Phenology.Zadok.Stage] > 0 \\\n",
    "          ORDER BY SimulationID, runDate\"    \n",
    "    #print(datetime.datetime.now())\n",
    "    dfReport = pd.read_sql_query(strSql, con, index_col=\"SimulationID\" )\n",
    "    #print(datetime.datetime.now())\n",
    "\n",
    "    # format the date columns\n",
    "    dfReport['runDate'] = pd.to_datetime(dfReport['runDate'], format=\"%Y-%m-%d\")\n",
    "\n",
    "    # create the SimId column\n",
    "    dfReport['SimID'] = dfReport.index\n",
    "    \n",
    "    #filter the data based on a date range\n",
    "    #do I need to make the run date an index column so tha we can quickly filter it\n",
    "    dfReport = dfReport[(dfReport['runDate'] >= startDate) & (dfReport['runDate'] <= endDate) ] \n",
    "\n",
    "    return dfReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filename(dbname):\n",
    "    '''\n",
    "    Takes the full path and filename for the database file, and creates the filename\n",
    "    that is used for the weather file, and to save the output.\n",
    "\n",
    "    Note:  cannot use the db filename as it doesn't have the long & lat that we require\n",
    "           need to manipulate the filename to add the underscrore '_' char\n",
    "           ONLY need to allow for negative (south) latitudes\n",
    "    '''\n",
    "    filename = os.path.basename(dbname)\n",
    "    filename = os.path.splitext(filename)[0]\n",
    "    nameparts = filename.split('-')\n",
    "    filename = nameparts[0] + '_-' + nameparts[1]\n",
    "    lat = '-' + nameparts[1]\n",
    "\n",
    "    return filename, lat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linint_3hrly_Temperature(tmax, tmin, xp, fp):\n",
    "    '''\n",
    "    Eight interpolations of the air temperature are calculated using \n",
    "    a three-hour correction factor.\n",
    "    For each air three-hour air temperature, a value is calculated.\n",
    "    The eight three-hour estimates are then averaged to obtain the daily value.\n",
    "    '''\n",
    "\n",
    "    #Local Variables\n",
    "    tot = 0.0            #sum_of of 3 hr interpolations\n",
    "    \n",
    "    for period in range(1, num3hr):\n",
    "        #get mean temperature for 3 hr period (oC)\n",
    "        tmean_3hour = tmin + (t_range_fract[period-1] * (tmax - tmin))\n",
    "        tot = tot + np.interp(tmean_3hour, xp,fp)\n",
    "        #print(\"tmean_3hour: \", tmean_3hour, \" - tot: \", tot)\n",
    "\n",
    "    return tot / num3hr;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_ApsimWeather(filename, latitude, startDate, endDate):\n",
    "    '''\n",
    "    Reads an apsim weather ('.met') file, removes the header information,\n",
    "    calculates and adds a date column (based on year and day), and the\n",
    "    average temperature (based on maxt and mint).\n",
    "    '''\n",
    "    import math\n",
    "\n",
    "    # these XYPairs are use when calculating Thermal Time \n",
    "    # and are specific to Wheat only\n",
    "    xp = [0, 26, 37]\n",
    "    fp = [0, 26, 0]\n",
    "    \n",
    "    lineNo = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            lineNo = lineNo + 1\n",
    "            if line.startswith('year'):\n",
    "                break;\n",
    "\n",
    "    # return the data using the starting line no (determined above)\n",
    "    # original column names=['year','day', 'radn', 'maxt', 'mint', 'rain']\n",
    "    metData = pd.read_table(filename, sep='\\s+', header=None, skiprows=lineNo+1,\n",
    "                            names=['year','dayofYear', 'radiation', 'maxTemp', 'minTemp', 'rain'])\n",
    "    \n",
    "    # add the calculated columns\n",
    "    metData['runDate'] = pd.to_datetime(metData['year'].astype(str) + \" \" + metData['dayofYear'].astype(str), format=\"%Y %j\")\n",
    "\n",
    "    #filter this file based on the dates we are working with\n",
    "    metData = metData[(metData['runDate'] >= startDate) & (metData['runDate'] <= endDate)] \n",
    "        \n",
    "    # this may need to be the thermal time, not just average temp\n",
    "    metData['avgTemp'] = (metData['maxTemp'] + metData['minTemp']) / 2\n",
    "\n",
    "    # calculate the Apsim Thermal Time\n",
    "    metData['ApsimTT'] = metData.apply(lambda x: linint_3hrly_Temperature(x['maxTemp'], x['minTemp'], xp, fp), axis=1)\n",
    "    \n",
    "    #convert the radiation from MJ/m2/day to Photosynthetically active radiation (PAR)\n",
    "    metData['PARIO'] = metData['radiation'] * 0.47\n",
    "\n",
    "    #convert the measurement unit for the radiation from MJ/m2/day to J/m2/day\n",
    "    metData['radnJ'] = metData['radiation'] * 1000000\n",
    "\n",
    "    metData['PQ'] = metData['PARIO'] / metData['avgTemp']\n",
    "\n",
    "    # calculation the day length\n",
    "    radians = math.pi/180\n",
    "    lambdaRadians = float(latitude) * radians\n",
    "\n",
    "    sinLAT = math.sin(lambdaRadians)\n",
    "    cosLAT = math.cos(lambdaRadians)\n",
    "    sinDMC = math.sin(radians * 23.45)\n",
    "\n",
    "    #print(\"radians: \", radians)\n",
    "    #print(\"lambdaRadians: \", lambdaRadians)\n",
    "    #print(\"sinLAT: \", sinLAT)\n",
    "    #print(\"cosLAT: \", cosLAT)\n",
    "    #print(\"sinDMC: \", sinDMC)    \n",
    "    \n",
    "    metData['sinDEC'] = -sinDMC * np.cos(2 * math.pi * (metData['dayofYear'] + 10) / 365)\n",
    "    metData['cosDEC'] = np.sqrt(1 - (metData['sinDEC'] * metData['sinDEC']))\n",
    "    metData['a'] = sinLAT * metData['sinDEC']\n",
    "    metData['b'] = cosLAT * metData['cosDEC']\n",
    "\n",
    "    metData['daylength'] = 12 * (1 + (2 / math.pi) * np.arcsin(metData['a']/metData['b']))\n",
    "\n",
    "    # calculate the Fraction Disfused Radiation (FDR)\n",
    "    metData['hour'] = np.mod(metData['dayofYear'], 1) * 24\n",
    "    metData['sinB'] = metData['a'] + metData['b'] * np.cos(2 * math.pi * (metData['hour'] - 12) / 24)\n",
    "    metData['SC'] = 1367 * (1 + 0.033 * np.cos(2 * math.pi * (metData['dayofYear'] - 10) / 365))\n",
    "    metData['sinINT'] = metData['a'] * metData['daylength'] + (24 * metData['b'] / math.pi) * \\\n",
    "                        np.cos((math.pi / 2) * ((metData['daylength'] / 12) - 1))\n",
    "\n",
    "    metData['Ta'] = metData['radnJ'] / (metData['sinINT'] * 3600 * metData['SC'])\n",
    "    metData['FDR'] = metData['Ta'] * -1.4545 + 1.2182\n",
    "\n",
    "    # calculate the Evapotranspiration\n",
    "    metData['vpsl'] = 238.102 * 17.32491 * ((metData['minTemp'] + metData['maxTemp']) /2) / \\\n",
    "                      (((metData['minTemp'] + metData['maxTemp']) / 2) + 238.102) ** 2\n",
    "    metData['ETpt'] = 1.26 * (metData['radnJ']  * (metData['vpsl'] / (metData['vpsl'] + 0.067))) / 2454000\n",
    "\n",
    "    \n",
    "    # sort the columns to be a little more logical\n",
    "    #cols=['year', 'dayofYear', 'runDate', 'dayLength', 'maxTemp', 'minTemp', 'avgTemp', 'ApsimTT', 'rain', \\\n",
    "    #      'PARIO', 'fracDiffusedRadn', 'vpsl', 'ETpt']\n",
    "    #metData = metData[cols]    \n",
    "    \n",
    "    return metData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weather_details(filename, latitude, startDate, endDate):\n",
    "    '''\n",
    "    Retrieves the weather data for the location (long,lat) specified in the dbname,\n",
    "    formats the data, and returns a dataframe\n",
    "    '''\n",
    "\n",
    "    fullfilename = metfile_sourcedir + \"/c_\" + filename + \".met\"\n",
    "    dfWeather = read_ApsimWeather(fullfilename, latitude, startDate, endDate)\n",
    "\n",
    "    return dfWeather\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data\n",
    "The following forms a single function:  def process_Apsim_dbfile(dbname):  \n",
    "#### NOTE:  dbname is defined at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"processing file: \", dbname)\n",
    "print(\"started at \", datetime.datetime.now())\n",
    "filename, latitude = get_filename(dbname)\n",
    "\n",
    "print(\"filename: \", filename)\n",
    "print(\"latitude: \", latitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the weather data from the weather '.met' file\n",
    "dfWeather = get_weather_details(filename, latitude, startDate, endDate)\n",
    "print(dfWeather.shape)\n",
    "print(dfWeather.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this will be part of the get_weather_details functionality, but is commented out so that I can check things\n",
    "#cols=['year', 'dayofYear', 'runDate', 'daylength', 'maxTemp', 'minTemp', 'avgTemp', 'ApsimTT', 'rain', \\\n",
    "#      'PARIO', 'PQ', 'FDR', 'vpsl', 'ETpt']\n",
    "#dfWeather = dfWeather[cols] \n",
    "outfilename = apsim_outfiledir + \"/\" + filename + \"_weather.csv\"\n",
    "dfWeather.to_csv(outfilename, encoding='utf-8', index=False)\n",
    "#dfWeather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the Simulation Details from the DB._Sumulation table\n",
    "dfSim = get_simulation_details(dbname) \n",
    "print(dfSim.shape)\n",
    "print(dfSim.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simIdStr = get_variety_SimIDs(dfSim, varietylist)\n",
    "simIdStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the Details from the DB.Report table\n",
    "dfReport = get_report_details(dbname, simIdStr, startDate, endDate)\n",
    "print(dfReport.shape)\n",
    "print(dfReport.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the data with the Simulation details, so that we can get the sow date\n",
    "# and filter it again\n",
    "dfCombined = dfReport.merge(dfSim, on=\"SimID\", how='left')\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sowing date (with current year)\n",
    "dfCombined['sowingdate'] = dfCombined['sowdate'] + '-' + dfCombined['runDate'].dt.year.map(str)\n",
    "dfCombined['sowingdate'] = pd.to_datetime(dfCombined['sowingdate'], format=\"%d-%b-%Y\")\n",
    "dfCombined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data from the Report details that we are not going to be looking at\n",
    "# ie, any data prior to our sow date for each year (should reduce size of data considerably)\n",
    "dfCombined = dfCombined[(dfCombined['runDate'] >= dfCombined['sowingdate'])] \n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-order and filter columns\n",
    "cols = ['SimID', 'long', 'lat', 'variety', 'sowdate', 'sowingdate', 'runDate', 'LAI', 'Biomass', 'Yield', \\\n",
    "        'ZadokStage', 'WSDR']\n",
    "dfCombined = dfCombined[cols] \n",
    "dfCombined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the report data with the weather data\n",
    "dfCombined = dfCombined.merge(dfWeather, on='runDate', how='left')\n",
    "dfCombined\n",
    "# filter the data based on the information we want\n",
    "#filterCols = ['SimID', 'runDate', 'ZadokStage', 'avgTemp']\n",
    "#dfSubData = dfCombined[filterCols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bins for the phases\n",
    "bins = [0, 7, 10, 31, 39, 65, 71, 87, 89, 90]\n",
    "group_names = ['01_Germinating', '02_Emerging', '03_Vegetative', '04_StemElongation',\n",
    "               '05_EarlyReproductive', '06_GrainSet', '07_GrainFilling', '08_Maturing', '09_Ripening']\n",
    "dfCombined['phases'] = pd.cut(dfCombined['ZadokStage'], bins, labels=group_names)\n",
    "dfCombined\n",
    "\n",
    "#might need to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to work out the Ripening phase\n",
    "# starts where 90 is maturity (start of ripening stage)\n",
    "dfCombined['cumAvgTemp'] = dfCombined.groupby(by=['SimID','sowingdate'])['avgTemp'].cumsum()\n",
    "dfCombined['cumApsimTT'] = dfCombined.groupby(by=['SimID','sowingdate'])['ApsimTT'].cumsum()\n",
    "dfCombined['cumRain'] = dfCombined.groupby(by=['SimID','sowingdate'])['rain'].cumsum()\n",
    "\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are cumulative calculations for each phase\n",
    "dfCombined['cumPhaseAvgTemp'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['avgTemp'].cumsum()\n",
    "dfCombined['cumPhaseApsimTT'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['ApsimTT'].cumsum()\n",
    "dfCombined['cumPhaseRain'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['rain'].cumsum()\n",
    "dfCombined['cumPhaseETpt'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['ETpt'].cumsum()\n",
    "dfCombined['cumPhasePARIO'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['PARIO'].cumsum()\n",
    "\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = dfCombined.columns.values.tolist()\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output a subset so I can look at the data\n",
    "cols = ['SimID', 'long', 'lat', 'variety', 'sowdate', 'sowingdate', 'runDate', 'year', 'dayofYear', \\\n",
    "        'maxTemp', 'minTemp', 'rain', 'avgTemp', 'ApsimTT', 'phases', 'daylength', 'radiation', \\\n",
    "        'LAI', 'Biomass', 'Yield', 'ZadokStage', 'WSDR', 'PARIO', 'radnJ', 'PQ', 'sinDEC', 'cosDEC', \\\n",
    "        'a', 'b', 'hour', 'sinB', 'SC', 'sinINT', 'Ta', 'FDR', 'vpsl', 'ETpt', \\\n",
    "        'cumavgTemp', 'cumApsimTT', 'cumRain', 'cumPhaseavgTemp', 'cumPhaseApsimTT', \\\n",
    "        'cumPhaseRain', 'cumPhaseETpt', 'cumPhasePARIO']\n",
    "dfCombined = dfCombined[cols]\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================\n",
    "# NEED TO CONVERT THE phases column to string so that I can add stage 10\n",
    "#==============================================================\n",
    "#dfData = dfCombined\n",
    "dfCombined['phases'].dtypes\n",
    "\n",
    "dfCombined['phases'] = dfCombined['phases'].astype(str)\n",
    "dfCombined['phases'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data \n",
    "#also where Zadok = 90 and cumPhaseApsimTT > 300 (except first record - need to keep this)\n",
    "#first record to be labelled '10_Harvest'\n",
    "dfCombined.loc[(dfCombined['ZadokStage'] == 90) & (dfCombined['cumPhaseApsimTT'] >= 300 ),'phases'] = '10_Harvest'\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombined.loc[dfCombined.groupby(['SimID','sowingdate','phases'])['cumPhaseApsimTT'].idxmin(),'firstHarvest'] = 1\n",
    "dfCombined.loc[(dfCombined['phases'] != '10_Harvest' ),'firstHarvest'] = 1\n",
    "dfCombined['firstHarvest'] = dfCombined.firstHarvest.fillna(0).astype(int)\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCombined = dfCombined[(dfCombined['firstHarvest'] == 1)]\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subData = dfCombined.loc[dfCombined['SimID'].isin([2,3,4])]\n",
    "outfilename = apsim_outfiledir + \"/filtered_\" + filename + \".csv\"\n",
    "subData.to_csv(outfilename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Need to determine the phases: \n",
    "•\tlength (no of days in phase), minTemp, maxTemp, and avgTemp,  \n",
    "•\tthe cumulativeAvgTemp at the end of each phase, (needs to be called TTAfterSowing)  \n",
    "•\tthe counts for number of day where temperatures are below or above specified values (refer to SIP_Temp discussion.docs for further details)  \n",
    "•\tthe average and cumulative rainfall   \n",
    "•\taverage radiation, cumulative radiation  \n",
    "•\taverage watersupplydemandratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should I add a column that can be a concatinated key\n",
    "#dfCombined['SimIDsowingdatephase'] = dfCombined['SimID'].map(str) + dfCombined['sowingdate'].map(str) + \\\n",
    "                                     dfCombined['phases']\n",
    "#dfCombined.loc[(dfCombined['phases'] != '10_Harvest' ),'firstHarvest'] = 1\n",
    "\n",
    "#dfCombined = dfCombined.set_index('SimIDsowingdatephase')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these are the figures for the season\n",
    "dfSummary = dfCombined.groupby(by=['SimID','sowingdate','phases'])['cumAvgTemp'].max().reset_index()\n",
    "dfSummary.columns = ['SimID', 'sowingdate', 'phases', 'season_cumAvgTemp']\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID','sowingdate','phases'])['cumApsimTT'].max().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'season_cumApsimTT']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID','sowingdate','phases'])['cumRain'].max().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'season_cumRain']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many days in each of the phases\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'dayCount']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "\n",
    "#what is the minimimum temperature for the phase\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['minTemp'].min().reset_index()\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "#dfSummary\n",
    "\n",
    "#what is the maximum temperature for the phase\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['maxTemp'].max().reset_index()\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "#dfSummary\n",
    "\n",
    "#what is the average of average temp for the phase\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['avgTemp'].mean().reset_index()\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "    \n",
    "#what is the average of average ApsimTT for the phase\n",
    "dfSum = dfCombined.groupby(by=['SimID','sowingdate','phases'])['ApsimTT'].mean().reset_index()\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geth the values for the last day in each phase \n",
    "dfSum = dfCombined.groupby(by=['SimID','sowingdate','phases'])['cumPhaseavgTemp'].max().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'cumavgTemp']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['cumPhaseApsimTT'].max().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'cumApsimTT']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['cumPhaseRain'].max().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'cumRain']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['WSDR'].mean().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'avgWSDR']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['cumPhaseETpt'].max().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'cumETpt']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['cumPhasePARIO'].max().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'cumPARIO']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['PARIO'].mean().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'avgPARIO']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['FDR'].mean().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'avgFDR']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['PQ'].mean().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'avgPQ']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['daylength'].mean().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'avgdaylength']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].min().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'startDate']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].max().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'endDate']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['Biomass'].last().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'Biomass']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['LAI'].last().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'LAI']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined.groupby(by=['SimID', 'sowingdate', 'phases'])['Yield'].last().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'Yield']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the counts of various miniumum temperatures\n",
    "dfSum = dfCombined[dfCombined['minTemp'] <= 0].groupby(by=['SimID','sowingdate','phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days<=0']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['minTemp'] <= -1].groupby(by=['SimID','sowingdate','phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days<=-1']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['minTemp'] <= -2].groupby(by=['SimID','sowingdate','phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days<=-2']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['minTemp'] <= -3].groupby(by=['SimID','sowingdate','phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days<=-3']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the counts of various maximum temperatures\n",
    "dfSum = dfCombined[dfCombined['maxTemp'] >= 30].groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days>=30']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['maxTemp'] >= 32].groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days>=32']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['maxTemp'] >= 34].groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days>=34']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['maxTemp'] >= 36].groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days>=36']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['maxTemp'] >= 38].groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days>=38']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSum = dfCombined[dfCombined['maxTemp'] >= 40].groupby(by=['SimID', 'sowingdate', 'phases'])['runDate'].count().reset_index()\n",
    "dfSum.columns = ['SimID', 'sowingdate', 'phases', 'days>=40']\n",
    "dfSummary = dfSummary.merge(dfSum, on=['SimID', 'sowingdate', 'phases'], how='left')\n",
    "\n",
    "dfSummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to marry back to Simulation details to get cultivar\n",
    "dfSummary = dfSummary.merge(dfSim, on=\"SimID\", how='left')\n",
    "#cols = dfSummary.columns.values.tolist()\n",
    "#print(cols)\n",
    "cols = ['SimID', 'variety', 'long', 'lat', 'sowingdate', 'phases', \n",
    "        'season_cumavgTemp', 'season_cumApsimTT', 'season_cumRain', 'startDate', 'endDate', \n",
    "        'dayCount', 'minTemp', 'maxTemp', 'avgTemp', 'ApsimTT', 'avgdaylength', \n",
    "        'cumavgTemp', 'cumApsimTT', 'cumRain', 'avgWSDR', 'cumETpt', 'cumPARIO', \n",
    "        'avgPARIO', 'avgFDR', 'avgPQ', 'Biomass', 'LAI', 'Yield', \n",
    "        'days<=0', 'days<=-1', 'days<=-2', 'days<=-3', \n",
    "        'days>=30', 'days>=32', 'days>=34', 'days>=36', 'days>=38', 'days>=40']\n",
    "dfSummary = dfSummary[cols]\n",
    "dfSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfilename = apsim_outfiledir + \"/filtered_\" + filename + \"_summary.csv\"\n",
    "dfSummary.to_csv(outfilename, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
