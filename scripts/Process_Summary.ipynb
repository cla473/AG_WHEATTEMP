{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the Summary Files\n",
    "\n",
    "This script will process the *_summary.csv files.  The will iterate through all of the files and generate a single file for a specific growth phase and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sourcedir = \"/OSM/CBR/AG_WHEATTEMP/work/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filename\n",
      "0  /OSM/CBR/AG_WHEATTEMP/work/output/113.60_-28.3...\n",
      "1  /OSM/CBR/AG_WHEATTEMP/work/output/113.70_-28.4...\n",
      "2  /OSM/CBR/AG_WHEATTEMP/work/output/113.70_-28.5...\n",
      "3  /OSM/CBR/AG_WHEATTEMP/work/output/113.75_-28.4...\n",
      "4  /OSM/CBR/AG_WHEATTEMP/work/output/113.75_-28.5...\n"
     ]
    }
   ],
   "source": [
    "filelist_df = pd.DataFrame(columns=['filename'])\n",
    "filelist_df.filename = sorted(sourcedir+'/'+f for f in os.listdir(sourcedir) if f.endswith('_summary.csv'))\n",
    "print(filelist_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = sourcedir + \"/filelist.txt\"\n",
    "filelist_df.to_csv(outfile, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filelist_df = pd.read_csv(outfilelist, header=None)\n",
    "filelist_df.columns=['filename']\n",
    "filelist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_summary_files(filelist, filter_phase, filter_year):\n",
    "    '''\n",
    "    processes an individual file and extracts information based on the phase and year that\n",
    "    is passed in\n",
    "    '''\n",
    "\n",
    "    outfilelist = sourcedir + \"/\" + filelist\n",
    "    filelist_df = pd.read_csv(outfilelist, header=None)\n",
    "    filelist_df.columns=['filename']    \n",
    "    \n",
    "    for filename in filelist_df.filename:\n",
    "        #print(\" ...file: \", filename)\n",
    "    \n",
    "        dfData = pd.read_csv(filename)\n",
    "        dfData = dfData[(dfData['phases'] == filter_phase)]\n",
    "        dfData['sowingdate'] = pd.to_datetime(dfData['sowingdate'], format=\"%Y-%m-%d\")\n",
    "        dfData['year'] = dfData['sowingdate'].dt.year\n",
    "        dfData['sowdate'] = dfData['sowingdate'].dt.strftime(\"%d-%B\")\n",
    "        dfData = dfData[(dfData['year'] == filter_year)]\n",
    "\n",
    "        cols = ['SimID', 'variety', 'long', 'lat', 'sowdate', 'phases', 'dayCount', \n",
    "                'maxTemp', 'avgTemp', 'days>=30', 'days>=32']\n",
    "        dfData = dfData[cols]\n",
    "\n",
    "        dfData.rename(columns={'days>=30': 'daysGTE30', 'days>=32': 'daysGTE32'}, inplace=True)\n",
    "\n",
    "        outfile = sourcedir + \"/\" + filter_phase + \"_\" + str(filter_year) + \".csv\"\n",
    "\n",
    "        \n",
    "        #NEED TO LOOK AT COLLATING THE LIST AND THEN SAVING IT AS SINGLE SAVE\n",
    "        #                DIFFERENT FILE FORMAT ALSO (FST PACKAGE ????)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if not os.path.isfile(outfile):\n",
    "            dfData.to_csv(outfile, header=True, encoding='utf-8', index=False)\n",
    "        else:\n",
    "            dfData.to_csv(outfile, header=False, mode='a', encoding='utf-8', index=False)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing started at  2018-08-08 13:53:51.811575\n",
      "Processs completed 2018-08-08 14:35:48.688472\n"
     ]
    }
   ],
   "source": [
    "# set some defaults to work with\n",
    "filelist = \"filelist.txt\"\n",
    "filter_phase = \"07_GrainFilling\"\n",
    "filter_year = 2017\n",
    "\n",
    "print(\"processing started at \", datetime.datetime.now())\n",
    "process_summary_files(filelist, filter_phase, filter_year)\n",
    "print(\"Processs completed\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.1",
   "language": "python",
   "name": "python-3.6.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
