{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scan Slurm Files\n",
    "\n",
    "This script will scan the slurm files for any errors, and get the name of the databases that had errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sourcedir = \"//flush1/cla473/AG_WHEATTEMP/scripts\"\n",
    "foundCount=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_df = pd.DataFrame(columns=['filename'])\n",
    "filelist_df.filename = sorted(sourcedir+'/'+f for f in os.listdir(sourcedir) if f.startswith('slurm'))\n",
    "print(filelist_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = filelist_df.filename[1]\n",
    "filename = \"//flush1/cla473/AG_WHEATTEMP/scripts/slurm-125600_10.out\"\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_getting_slurm_errors(infile, outfile):\n",
    "    '''\n",
    "    reads the slurm file and outputs the name of the dbfiles where there was an error\n",
    "    '''\n",
    "    \n",
    "    with open(infile, \"r\") as fp:\n",
    "        data = fp.readlines()\n",
    "    \n",
    "    #print(\"no of lines: \", len(data))\n",
    "    \n",
    "    #note:  a clean file has 150 lines, each working group has 3 lines\n",
    "    global foundCount\n",
    "    for i in range(2, len(data)):\n",
    "        if data[i].startswith(\"Traceback\"):\n",
    "            if data[i-2].startswith(\"processing\"):\n",
    "                foundCount += 1\n",
    "                outstring = data[i-2].split(\"/\")\n",
    "                print(foundCount, \": \", outstring[-1].strip())\n",
    "        #if data[i].startswith(\"pandas.io\"):\n",
    "        #    print(data[i])\n",
    "    \n",
    "    #outfile = sourcedir + \"/\" + filter_phase + \"_\" + str(filter_year) + \".csv\"\n",
    "\n",
    "    #if not os.path.isfile(outfile):\n",
    "    #    dfData.to_csv(outfile, header=True, encoding='utf-8', index=False)\n",
    "    #else:\n",
    "    #    dfData.to_csv(outfile, header=False, mode='a', encoding='utf-8', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foundCount = 0\n",
    "count = 0\n",
    "for filename in filelist_df.filename:\n",
    "    count += 1\n",
    "    read_file_getting_slurm_errors(filename, \"noname\")\n",
    "\n",
    "    if count >= 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.1",
   "language": "python",
   "name": "python-3.6.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
