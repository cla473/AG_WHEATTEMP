{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Growth Phases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks at the SQLite Databases generated by Apsim X (Next Gen) for 109 Wheat varieties, 10 differing sow dates for  57,434 locations/sites across Australia.  \n",
    "Each database file covers one (1) site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these are required for calculations of thermal time\n",
    "num3hr = int(24 / 3)\n",
    "#print(\"num3hr: \", num3hr)    \n",
    "t_range_fract = []\n",
    "\n",
    "# pre calculate t_range_fract for speed reasons\n",
    "for period in range(num3hr):\n",
    "    calcValue = 0.92105 \\\n",
    "                + 0.1140 * period \\\n",
    "                - 0.0703 * math.pow(period, 2) \\\n",
    "                + 0.0053 * math.pow(period, 3)\n",
    "    t_range_fract.append(calcValue)\n",
    "\n",
    "#print(\"t_range_fract: \", t_range_fract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linint_3hrly_Temperature(tmax, tmin, xp, fp):\n",
    "    '''\n",
    "    Eight interpolations of the air temperature are calculated using \n",
    "    a three-hour correction factor.\n",
    "    For each air three-hour air temperature, a value is calculated.\n",
    "    The eight three-hour estimates are then averaged to obtain the daily value.\n",
    "    '''\n",
    "\n",
    "    #Local Variables\n",
    "    tot = 0.0            #sum_of of 3 hr interpolations\n",
    "    \n",
    "    for period in range(1, num3hr):\n",
    "        #get mean temperature for 3 hr period (oC)\n",
    "        #tmean_3hour = temp_3hr(tmax, tmin, period)\n",
    "        tmean_3hour = tmin + (t_range_fract[period-1] * (tmax - tmin))\n",
    "        #tot = tot + ttFn.valueIndexed(tmean_3hour)\n",
    "        tot = tot + np.interp(tmean_3hour, xp,fp)\n",
    "        \n",
    "        #print(\"tmean_3hour: \", tmean_3hour, \" - tot: \", tot)\n",
    "\n",
    "    return tot / num3hr;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_ApsimWeather(filename, lat):\n",
    "    '''\n",
    "    Reads an apsim weather ('.met') file, removes the header information,\n",
    "    calculates and adds a date column (based on year and day), and the\n",
    "    average temperature (based on maxt and mint).\n",
    "    '''\n",
    "    import math\n",
    "\n",
    "    # these XYPairs are use when calculating Thermal Time \n",
    "    # and are specific to Wheat only\n",
    "    xp = [0, 26, 37]\n",
    "    fp = [0, 26, 0]\n",
    "    \n",
    "    lineNo = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            lineNo = lineNo + 1\n",
    "            if line.startswith('year'):\n",
    "                break;\n",
    "\n",
    "    # return the data using the starting line no (determined above)\n",
    "    # original column names=['year','day', 'radn', 'maxt', 'mint', 'rain']\n",
    "    metData = pd.read_table(filename, sep='\\s+', header=None, skiprows=lineNo+1,\n",
    "                            names=['year','dayofYear', 'radiation', 'maxTemp', 'minTemp', 'rain'])\n",
    "    \n",
    "    # add the calculated columns\n",
    "    metData['runDate'] = pd.to_datetime(metData['year'].astype(str) + \" \" + metData['dayofYear'].astype(str), format=\"%Y %j\")\n",
    "\n",
    "    # this may need to be the thermal time, not just average temp\n",
    "    metData['avgTemp'] = (metData['maxTemp'] + metData['minTemp']) / 2\n",
    "\n",
    "    #convert the radiation from MJ/m2/day to Photosynthetically active radiation (PAR)\n",
    "    metData['PARIO'] = metData['radiation'] * 0.47\n",
    "\n",
    "    #convert the measurement unit for the radiation from MJ/m2/day to J/m2/day\n",
    "    metData['radnJ'] = metData['radiation'] * 1000000\n",
    "\n",
    "\n",
    "    # calculation the day length\n",
    "    radians = math.pi/180\n",
    "    lambdaRadians = float(latitude) * radians\n",
    "\n",
    "    sinLAT = math.sin(lambdaRadians)\n",
    "    cosLAT = math.cos(lambdaRadians)\n",
    "    sinDMC = math.sin(radians * 23.45)\n",
    "\n",
    "    #print(\"radians: \", radians)\n",
    "    #print(\"lambdaRadians: \", lambdaRadians)\n",
    "    #print(\"sinLAT: \", sinLAT)\n",
    "    #print(\"cosLAT: \", cosLAT)\n",
    "    #print(\"sinDMC: \", sinDMC)    \n",
    "    \n",
    "    metData['sinDEC'] = -sinDMC * np.cos(2 * math.pi * (metData['dayofYear'] + 10) / 365)\n",
    "    metData['cosDEC'] = np.sqrt(1 - (metData['sinDEC'] * metData['sinDEC']))\n",
    "    metData['a'] = sinLAT * metData['sinDEC']\n",
    "    metData['b'] = cosLAT * metData['cosDEC']\n",
    "\n",
    "    metData['daylength'] = 12 * (1 + (2 / math.pi) * np.arcsin(metData['a']/metData['b']))\n",
    "\n",
    "    # calculate the Fraction Disfused Radiation (FDR)\n",
    "    metData['hour'] = np.mod(metData['dayofYear'], 1) * 24\n",
    "    metData['sinB'] = metData['a'] + metData['b'] * np.cos(2 * math.pi * (metData['hour'] - 12) / 24)\n",
    "    metData['SC'] = 1367 * (1 + 0.033 * np.cos(2 * math.pi * (metData['dayofYear'] - 10) / 365))\n",
    "    metData['sinINT'] = metData['a'] * metData['daylength'] + (24 * metData['b'] / math.pi) * \\\n",
    "                        np.cos((math.pi / 2) * ((metData['daylength'] / 12) - 1))\n",
    "\n",
    "    metData['Ta'] = metData['radnJ'] / (metData['sinINT'] * 3600 * metData['SC'])\n",
    "    metData['FDR'] = metData['Ta'] * -1.6 +1.32\n",
    "\n",
    "    # calculate the Evapotranspiration\n",
    "    metData['vpsl'] = 238.102 * 17.32491 * ((metData['minTemp'] + metData['maxTemp']) /2) / \\\n",
    "                      (((metData['minTemp'] + metData['maxTemp']) / 2) + 238.102) ** 2\n",
    "    metData['ETpt'] = 1.26 * (metData['radnJ']  * (metData['vpsl'] / (metData['vpsl'] + 0.067))) / 2454000\n",
    "\n",
    "    metData['ApsimTT'] = metData.apply(lambda x: \\\n",
    "                                       linint_3hrly_Temperature(x['maxTemp'], x['minTemp'], xp, fp), axis=1)\n",
    "    \n",
    "\n",
    "    # filter the unwanted columns and re order remaining columnsto be a little more logical\n",
    "    filterCols=['year', 'dayofYear', 'runDate', 'daylength', 'maxTemp', 'minTemp', \\\n",
    "                'avgTemp', 'ApsimTT', 'rain', 'PARIO', 'FDR', 'vpsl', 'ETpt']\n",
    "    metData = metData[filterCols]    \n",
    "    \n",
    "    return metData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filename_longitide_latitude(fullfilename):\n",
    "    '''\n",
    "    Takes the full path and filename for the weather file, and get the\n",
    "    latitude from that name\n",
    "    >>> get_latitude_from_filename(\"/OSM/CBR/AG_WHEATTEMP/work/ApsimNG-test/APSIM_run/met/c_113.75_-28.50.met\n",
    "\")\n",
    "    c_113.75_-28.50.met -28.50\n",
    "    '''\n",
    "    name = os.path.basename(fullfilename)\n",
    "    name = os.path.splitext(name)[0]\n",
    "    nameparts = name.split('_')\n",
    "    long = nameparts[1] \n",
    "    lat = nameparts[2]\n",
    "\n",
    "    return name, long, lat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data\n",
    "The following forms a single function:  def process_Apsim_dbfile(dbname):  \n",
    "#### NOTE:  dbname is defined at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the working directories\n",
    "metfile_sourcedir = \"/OSM/CBR/AG_WHEATTEMP/work/ApsimNG-test/APSIM_run/met\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filename\n",
      "0  /OSM/CBR/AG_WHEATTEMP/work/ApsimNG-test/APSIM_...\n",
      "1  /OSM/CBR/AG_WHEATTEMP/work/ApsimNG-test/APSIM_...\n",
      "2  /OSM/CBR/AG_WHEATTEMP/work/ApsimNG-test/APSIM_...\n",
      "3  /OSM/CBR/AG_WHEATTEMP/work/ApsimNG-test/APSIM_...\n",
      "4  /OSM/CBR/AG_WHEATTEMP/work/ApsimNG-test/APSIM_...\n",
      "/OSM/CBR/AG_WHEATTEMP/work/ApsimNG-test/APSIM_run/met/c_113.75_-28.50.met\n"
     ]
    }
   ],
   "source": [
    "dbfile_df = pd.DataFrame(columns=['filename'])\n",
    "dbfile_df.filename = sorted(metfile_sourcedir+'/'+f for f in os.listdir(metfile_sourcedir) if f.endswith('.met'))\n",
    "print(dbfile_df.head())\n",
    "fullfilename = dbfile_df.filename[4]\n",
    "print(fullfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file:  /OSM/CBR/AG_WHEATTEMP/work/ApsimNG-test/APSIM_run/met/c_113.75_-28.50.met\n",
      "started at  2018-08-01 08:09:11.091826\n",
      "filename:  c_113.75_-28.50\n",
      "longitude:  113.75\n",
      "latitude:  -28.50\n"
     ]
    }
   ],
   "source": [
    "print(\"processing file: \", fullfilename)\n",
    "print(\"started at \", datetime.datetime.now())\n",
    "filename, longitude, latitude = get_filename_longitide_latitude(fullfilename)\n",
    "\n",
    "print(\"filename: \", filename)\n",
    "print(\"longitude: \", longitude)\n",
    "print(\"latitude: \", latitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43038, 13)\n",
      "   year  dayofYear    runDate  daylength  maxTemp  minTemp  avgTemp  \\\n",
      "0  1900          1 1900-01-01  13.777211     32.4     13.2     22.8   \n",
      "1  1900          2 1900-01-02  13.769855     32.4     13.2     22.8   \n",
      "2  1900          3 1900-01-03  13.761885     32.4     13.2     22.8   \n",
      "3  1900          4 1900-01-04  13.753310     32.4     13.2     22.8   \n",
      "4  1900          5 1900-01-05  13.744134     32.4     13.2     22.8   \n",
      "\n",
      "     ApsimTT  rain  PARIO       FDR      vpsl       ETpt  \n",
      "0  15.694127   0.0  15.04  0.146049  1.381701  15.670443  \n",
      "1  15.694127   0.0  15.04  0.145442  1.381701  15.670443  \n",
      "2  15.694127   0.0  15.04  0.144761  1.381701  15.670443  \n",
      "3  15.694127   0.0  15.04  0.144007  1.381701  15.670443  \n",
      "4  15.694127   0.0  15.04  0.143178  1.381701  15.670443  \n"
     ]
    }
   ],
   "source": [
    "# retrieve the weather data from the weather '.met' file\n",
    "dfWeather = read_ApsimWeather(fullfilename, latitude)\n",
    "print(dfWeather.shape)\n",
    "print(dfWeather.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is so that we can check the calculations and see if everything is correct\n",
    "\n",
    "outfilename = metfile_sourcedir + \"/\" + filename + \"_calcs.csv\"\n",
    "dfWeather.to_csv(outfilename, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will be part of the get_weather_details functionality, but is commented out so that I can check things\n",
    "cols=['year', 'dayofYear', 'runDate', 'daylength', 'maxTemp', 'minTemp', 'avgTemp', 'ApsimTT', 'rain', \\\n",
    "      'PARIO', 'FDR', 'vpsl', 'ETpt']\n",
    "dfWeather = dfWeather[cols] \n",
    "dfWeather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the Simulation Details from the DB._Sumulation table\n",
    "dfSim = get_simulation_details(dbname) \n",
    "print(dfSim.shape)\n",
    "print(dfSim.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the Details from the DB.Report table\n",
    "dfReport = get_report_details(dbname)\n",
    "print(dfReport.shape)\n",
    "print(dfReport.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine the data with the Simulation details, so that we can get the sow date\n",
    "# and filter it again\n",
    "dfCombined = dfReport.merge(dfSim, on=\"SimID\", how='left')\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a sowing date (with current year)\n",
    "dfCombined['sowingdate'] = dfCombined['sowdate'] + '-' + dfCombined['runDate'].dt.year.map(str)\n",
    "dfCombined['sowingdate'] = pd.to_datetime(dfCombined['sowingdate'], format=\"%d-%b-%Y\")\n",
    "dfCombined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter the data from the Report details that we are not going to be looking at\n",
    "# ie, any data prior to our sow date for each year (should reduce size of data considerably)\n",
    "dfCombined = dfCombined[(dfCombined['runDate'] >= dfCombined['sowingdate'])] \n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#re-order and filter columns\n",
    "cols = ['SimID', 'long', 'lat', 'variety', 'sowdate', 'sowingdate', 'runDate', 'LAI', 'Biomass', 'Yield', \\\n",
    "        'ZadokStage', 'WaterSupplyDemandRatio']\n",
    "dfCombined = dfCombined[cols] \n",
    "dfCombined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine the report data with the weather data\n",
    "dfCombined = dfCombined.merge(dfWeather, on='runDate', how='left')\n",
    "dfCombined\n",
    "# filter the data based on the information we want\n",
    "#filterCols = ['SimID', 'runDate', 'ZadokStage', 'avgTemp']\n",
    "#dfSubData = dfCombined[filterCols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create bins for the phases\n",
    "bins = [0, 7, 10, 31, 39, 65, 71, 87, 89, 90]\n",
    "group_names = ['01_Germinating', '02_Emerging', '03_Vegetative', '04_StemElongation',\n",
    "               '05_EarlyReproductive', '06_GrainSet', '07_GrainFilling', '08_Maturing', '09_Ripening']\n",
    "dfCombined['phases'] = pd.cut(dfCombined['ZadokStage'], bins, labels=group_names)\n",
    "dfCombined\n",
    "\n",
    "#might need to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to work out the Ripening phase\n",
    "# starts where 90 is maturity (start of ripening stage)\n",
    "dfCombined['cumApsimTT'] = dfCombined.groupby(by=['SimID','sowingdate'])['ApsimTT'].cumsum()\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These are cumulative calculations for each phase\n",
    "dfCombined['cumPhaseAvgTemp'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['avgTemp'].cumsum()\n",
    "dfCombined['cumPhaseApsimTT'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['ApsimTT'].cumsum()\n",
    "dfCombined['cumPhaseRain'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['rain'].cumsum()\n",
    "dfCombined['cumPhaseETpt'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['ETpt'].cumsum()\n",
    "dfCombined['cumPhasePARIO'] = dfCombined.groupby(by=['SimID','sowingdate', 'phases'])['PARIO'].cumsum()\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output a subset so I can look at the data\n",
    "cols = ['SimID', 'long', 'lat', 'variety', 'sowdate', 'sowingdate', 'runDate', 'year', 'dayofYear', \\\n",
    "        'daylength', 'ZadokStage', 'phases', 'maxTemp', 'minTemp', 'avgTemp', 'cumPhaseAvgTemp', \\\n",
    "        'ApsimTT', 'cumApsimTT', 'cumPhaseApsimTT', 'rain', 'cumPhaseRain', 'PARIO', 'cumPhasePARIO', \\\n",
    "        'FDR', 'vpsl', 'ETpt', 'cumPhaseETpt', 'LAI', 'Biomass', 'Yield','WaterSupplyDemandRatio']\n",
    "dfCombined = dfCombined[cols]\n",
    "dfCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subData = dfCombined.loc[dfCombined['SimID'].isin([2,3,4])]\n",
    "outfilename = apsim_outfiledir + \"/sim123_cum_\" + filename + \".csv\"\n",
    "subData.to_csv(outfilename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==============================================================\n",
    "# TAKE A COPY OF THE ABOVE DATASET SO IT DOESN'T GET MESSED UP\n",
    "#==============================================================\n",
    "#dfData = dfCombined\n",
    "subData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter the data \n",
    "#also where Zadok = 90 and cumPhaseApsimTT > 300 (except first record - need to keep this)\n",
    "#first record to be labelled '10_Harvest'\n",
    "subData = dfCombined[cols]\n",
    "subData.loc[(subData['ZadokStage'] == 90) & (subData['cumPhaseApsimTT'] >= 300 ),'phases'] = '10_Harvest'\n",
    "subData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subData.loc[(subData['ZadokStage'] == 90) & (subData['cumPhaseApsimTT'] >= 300 ),'phases'] = '10_Harvest'\n",
    "subData['phases'] = np.where((subData['ZadokStage'] == 90 & subData['cumPhaseApsimTT'] >= 300), '10_Harvest', subData['phases'])\n",
    "subData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Need to determine the phases: \n",
    "•\tlength (no of days in phase), minTemp, maxTemp, and avgTemp,  \n",
    "•\tthe cumulativeAvgTemp at the end of each phase, (needs to be called TTAfterSowing)  \n",
    "•\tthe counts for number of day where temperatures are below or above specified values (refer to SIP_Temp discussion.docs for further details)  \n",
    "•\tthe average and cumulative rainfall   \n",
    "•\taverage radiation, cumulative radiation  \n",
    "•\taverage watersupplydemandratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# eliminate those records where the phase is Nan\n",
    "#dfSubData.dropna(subset=['phases'], inplace=True)\n",
    "#dfSubData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a function to get the stats for group\n",
    "def get_stats(group):\n",
    "    return {'min': group.min(), 'max': group.max(), 'mean': group.mean(), 'count': group.count()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#should I add a column that can be a concatinated key\n",
    "dfSubData['SimIdSowingdatePhase'] = dfSubData['SimId'].map(str) + \\ \n",
    "    dfSubData['sowingdate'].map(str) + dfSubData['phases']\n",
    "\n",
    "#apply the get_stats function to each phase bin\n",
    "dfSubData['ZadokStage'].groupby(dfSubData['SimIdSowingdatePhase']).apply(get_stats).unstack()\n",
    "dfSubData,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how many days in each of the phases\n",
    "newData1.groupby(['SimIdSowingdatePhase'].count().reset_index()\n",
    "\n",
    "#what is the minimimum temperature for the phase\n",
    "newData1.groupby(['SimIdSowingdatePhase'])['minTemp'].min().reset_index()\n",
    "#what is the maximum temperature for the phase\n",
    "newData1.groupby(['SimIdSowingdatePhase'])['maxTemp'].max().reset_index()\n",
    "\n",
    " newData1.groupby(['SimIdSowingdatePhase'])['biomass'].max().reset_index()\n",
    "\n",
    "#what is the average of average temp for the phase\n",
    "newData1.groupby(['SimIdSowingdatePhase'])['avgTemp'].mean().reset_index()\n",
    "\n",
    "#what is the average of average daily radiation for the phase\n",
    "#newData1.groupby(['SimIdSowingdatePhase'])['radn'].mean().reset_index()\n",
    "\n",
    "#what is the cumulative rainfall for each phase\n",
    "newData1.groupby(by=['SimIdSowingdatePhase'])['rain'].cumsum()\n",
    "\n",
    "newData1.groupby(by=['SimIdSowingdatePhase'])['ETpt'].cumsum()\n",
    "\n",
    "newData1.groupby(by=['SimIdSowingdatePhase'])['PARIO'].mean().reset_index()\n",
    "newData1.groupby(by=['SimIdSowingdatePhase'])['PARIO'].cumsum()\n",
    "\n",
    "newData1.groupby(by=['SimIdSowingdatePhase'])['PQDay'].mean.reset_index()\n",
    "newData1.groupby(by=['SimIdSowingdatePhase'])['daylengh'].mean.reset_index()\n",
    "\n",
    "#need to get the values for the last day in each phase:\n",
    "startdate, enddate, DAS, LAI, Biomass, Yield\n",
    "                \n",
    "                 \n",
    "#what is the average of average watersupplydemandratio for the phase\n",
    "newData1.groupby(['SimIdSowingdatePhase'])['watersupplydemandratio'].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the counts of various miniumum temperatures\n",
    "newData1[newData1['minTemp'] <= 0].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['minTemp'] <= -1].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['minTemp'] <= -2].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['minTemp'] <= -3].groupby['SimIdSowingdatePhase'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the counts of various maximum temperatures\n",
    "newData1[newData1['maxTemp'] >= 30].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['maxTemp'] >= 32].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['maxTemp'] >= 34].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['maxTemp'] >= 36].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['maxTemp'] >= 38].groupby['SimIdSowingdatePhase'].count()\n",
    "newData1[newData1['maxTemp'] >= 40].groupby['SimIdSowingdatePhase'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to add back in the longitude, latitude, variety from dfSim\n",
    "newData2 = newData2.merge(dfSim, on=['SimID', 'sowdate'], how='left')\n",
    "filterCols = ['SimID', 'long', 'lat', 'variety', 'sowdate', 'TTAfterSowing']\n",
    "newData2 = newData2[filterCols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfilename = apsim_outfiledir + \"/\" + filename + \"_zadok.csv\"\n",
    "newData2.to_csv(outfilename, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
